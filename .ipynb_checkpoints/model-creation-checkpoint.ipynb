{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarND Behavioral Cloning Project\n",
    "\n",
    "This project is about training a neural network to drive a car on a simulator using data recorded from a humman driver.\n",
    "\n",
    "This notebook will be used to create the model to be used in driving the car on the simulator.\n",
    "\n",
    "The inputs come in three images right, central and left cameras.\n",
    "\n",
    "The first thing to do is to clean, then oganize the dataset, and save it to pickle file. for posterior use.\n",
    "\n",
    "The file driving_log.csv contains steering angles and the left, right and center images associated to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not(os.path.exists('train.csv') and os.path.exists('validation.csv')):\n",
    "\n",
    "    path_to_replace = \"C:\\\\Users\\\\eduardo\\\\Documents\\\\SelfDrivingCar\\\\simulator-windows-64\\\\\"\n",
    "\n",
    "    def ReplaceWrongPath(value):\n",
    "        return value.replace(path_to_replace, \"\").replace(\"\\\\\", \"/\").replace(\" data\", \"data\")\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_train_left = []\n",
    "    y_train_left = []\n",
    "    X_train_right = []\n",
    "    y_train_right = []\n",
    "\n",
    "    with open('./data/driving_log.csv', 'r') as csv_file_in:\n",
    "\n",
    "        csv_reader = csv.DictReader(csv_file_in)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            steering = float(row['steering'])\n",
    "\n",
    "            #center image\n",
    "            path = './data/' + ReplaceWrongPath(row['center'].strip())        \n",
    "            X_train.append(path)\n",
    "            y_train.append(steering)\n",
    "            continue\n",
    "            \n",
    "            if steering == 0:\n",
    "                #left image\n",
    "                path = './data/' + ReplaceWrongPath(row['left'].strip())\n",
    "                steering_left = steering - 0.2\n",
    "\n",
    "                X_train_left.append(path)\n",
    "                y_train_left.append(steering_left)\n",
    "\n",
    "               #right image\n",
    "                path = './data/' + ReplaceWrongPath(row['right'].strip())\n",
    "                steering_right = steering + 0.2\n",
    "\n",
    "                X_train_right.append(path)\n",
    "                y_train_right.append(steering_right)\n",
    "\n",
    "            elif steering < 0:\n",
    "                #left image\n",
    "                path = './data/' + ReplaceWrongPath(row['left'].strip())\n",
    "                steering_left = steering * 0.8\n",
    "\n",
    "                X_train_left.append(path)\n",
    "                y_train_left.append(steering_left)\n",
    "\n",
    "                #right image\n",
    "                path = './data/' + ReplaceWrongPath(row['right'].strip())\n",
    "                steering_right = steering * 1.2\n",
    "                steering_right = steering_right if steering_right > 1 else 1\n",
    "\n",
    "                X_train_right.append(path)\n",
    "                y_train_right.append(steering_right)\n",
    "            else:\n",
    "                #left image\n",
    "                path = './data/' + ReplaceWrongPath(row['left'].strip())\n",
    "                steering_left = steering * 1.2\n",
    "                steering_left = steering_left if steering_left < -1 else -1\n",
    "\n",
    "                X_train_left.append(path)\n",
    "                y_train_left.append(steering_left)\n",
    "\n",
    "                #right image\n",
    "                path = './data/' + ReplaceWrongPath(row['right'].strip())\n",
    "                steering_right = steering * 0.8\n",
    "\n",
    "                X_train_right.append(path)\n",
    "                y_train_right.append(steering_right)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    [X_train.append(item) for item in X_train_left]\n",
    "    [X_train.append(item) for item in X_train_right]\n",
    "    [y_train.append(item) for item in y_train_left]\n",
    "    [y_train.append(item) for item in y_train_right]\n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "    with open('train.csv', 'w') as csv_file_train:\n",
    "\n",
    "        fieldnames = ['path','steering']\n",
    "        writer = csv.DictWriter(csv_file_train, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for i in range(len(X_train)):\n",
    "            path, steering = X_train[i], y_train[i]\n",
    "            writer.writerow({'path': path, 'steering': steering})\n",
    "\n",
    "    with open('validation.csv', 'w') as csv_file_train:\n",
    "\n",
    "        fieldnames = ['path','steering']\n",
    "        writer = csv.DictWriter(csv_file_train, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for i in range(len(X_validation)):\n",
    "            path, steering = X_validation[i], y_validation[i]\n",
    "            writer.writerow({'path': path, 'steering': steering})\n",
    "\n",
    "    print(\"processing done\")\n",
    "else:\n",
    "    print(\"files exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def turn_linear_to_logistic(steering, n_classes):\n",
    "    interval = 2/n_classes\n",
    "    classes = []\n",
    "    lower_bound = -1\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        upper_bound = lower_bound + interval if i < (n_classes-1) else 1\n",
    "        classes.append(1 if steering > lower_bound and steering < upper_bound else 0)\n",
    "        lower_bound += interval\n",
    "        \n",
    "    return np.array(classes)\n",
    "    \n",
    "    \n",
    "break_classes = 5\n",
    "X_train_left = None\n",
    "y_train_left = None\n",
    "X_train_right = None\n",
    "y_train_right = None\n",
    "\n",
    "X_train= []\n",
    "y_train = []\n",
    "\n",
    "with open('train.csv', 'r') as csv_file_train:\n",
    "    \n",
    "    csv_reader = csv.DictReader(csv_file_train)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        b,g,r = cv2.split(cv2.imread(row['path']))\n",
    "        X_train.append(row['path'])\n",
    "        y_train.append(turn_linear_to_logistic(float(row['steering']), break_classes))\n",
    "        \n",
    "\n",
    "X_validation = []\n",
    "y_validation = []\n",
    "\n",
    "with open('validation.csv', 'r') as csv_file_val:\n",
    "    \n",
    "    csv_reader = csv.DictReader(csv_file_val)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        b,g,r = cv2.split(cv2.imread(row['path']))\n",
    "        X_validation.append(row['path'])\n",
    "        y_validation.append(turn_linear_to_logistic(float(row['steering']), break_classes))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAGHCAYAAAB8hmJnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4694447b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ys = [np.argmax(y) for y in y_train]\n",
    "plt.hist(ys, bins=len(y_train[0]))\n",
    "plt.title(\"Training data\")\n",
    "plt.xlabel(\"Angles\")\n",
    "plt.ylabel(\"# of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(image_data):\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    img_min = 0\n",
    "    img_max = 255\n",
    "    return a + ( ( (image_data - img_min)*(b - a) )/( img_max - img_min ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "#### VGG with drop out, batch normalition\n",
    "\n",
    "#### 20 EPOCHS Adam optimizer linear regression\n",
    "\n",
    "#### Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Dropout, Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "input_tensor = Input(shape=(160, 320, 3))\n",
    "croped_input_img = Cropping2D(cropping=((60, 20), (0, 0)))(input_tensor)\n",
    "base_model = VGG16(input_tensor=croped_input_img, weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "top_model = base_model.output\n",
    "top_model = Flatten()(top_model)\n",
    "top_model = Dense(1024)(top_model)\n",
    "top_model = BatchNormalization()(top_model)\n",
    "top_model = Activation('relu')(top_model)\n",
    "top_model = Dropout(0.5)(top_model)\n",
    "top_model = Dense(1024)(top_model)\n",
    "top_model = BatchNormalization()(top_model)\n",
    "top_model = Activation('relu')(top_model)\n",
    "top_model = Dropout(0.5)(top_model)\n",
    "top_model = Dense(1)(top_model)\n",
    "top_model = BatchNormalization()(top_model)\n",
    "predictions = Activation('tanh')(top_model)\n",
    "\n",
    "model = Model(input=input_tensor, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import merge, ZeroPadding2D, Cropping2D, Convolution2D, MaxPooling2D, Input, Flatten, Dense, Activation, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def AddConvLayer(features, kernel, input_layer):\n",
    "    complex_layer = ZeroPadding2D((1,1))(input_layer)\n",
    "    complex_layer = Convolution2D(features, kernel[0], kernel[1], activation='relu')(complex_layer)\n",
    "    complex_layer = Dropout(0.5)(complex_layer)\n",
    "    complex_layer = ZeroPadding2D((1,1))(complex_layer)\n",
    "    complex_layer = Convolution2D(features, kernel[0], kernel[1], activation='relu')(complex_layer)\n",
    "    complex_layer = Dropout(0.5)(complex_layer)\n",
    "    complex_layer = MaxPooling2D((2,2), strides=(2,2))(complex_layer)\n",
    "    return complex_layer\n",
    "\n",
    "def AddDenseLayer(neurons, depth, input_conv_layer):\n",
    "    dense_layer = Flatten()(input_conv_layer)\n",
    "    for i in range(depth):\n",
    "        dense_layer = Dense(neurons, activation='relu')(dense_layer)\n",
    "        dense_layer = Dropout(0.5)(dense_layer)\n",
    "    return dense_layer\n",
    "\n",
    "\n",
    "input_img = Input(shape=(160, 320, 3))\n",
    "croped_input_img = Cropping2D(cropping=((60, 20), (0, 0)))(input_img)\n",
    "\n",
    "tower_1 = AddConvLayer(6, (3, 2), croped_input_img)\n",
    "tower_1 = AddConvLayer(6, (3, 2), tower_1)\n",
    "tower_1 = AddConvLayer(6, (3, 2), tower_1)\n",
    "tower_1 = AddConvLayer(16, (3, 2), tower_1)\n",
    "tower_1 = AddConvLayer(16, (3, 2), tower_1)\n",
    "tower_1 = AddConvLayer(16, (3, 2), tower_1)\n",
    "tower_1 = AddDenseLayer(120, 2, tower_1)\n",
    "\n",
    "tower_2 = AddConvLayer(6, (3, 3), croped_input_img)\n",
    "tower_2 = AddConvLayer(6, (3, 3), tower_2)\n",
    "tower_2 = AddConvLayer(6, (3, 3), tower_2)\n",
    "tower_2 = AddConvLayer(16, (3, 3), tower_2)\n",
    "tower_2 = AddConvLayer(16, (3, 3), tower_2)\n",
    "tower_2 = AddConvLayer(16, (3, 3), tower_2)\n",
    "tower_2 = AddDenseLayer(120, 2, tower_2)\n",
    "\n",
    "tower_3 = AddConvLayer(6, (5, 2), croped_input_img)\n",
    "tower_3 = AddConvLayer(6, (5, 2), tower_3)\n",
    "tower_3 = AddConvLayer(16, (5, 2), tower_3)\n",
    "tower_3 = AddConvLayer(16, (5, 2), tower_3)\n",
    "tower_3 = AddDenseLayer(120, 2, tower_3)\n",
    "\n",
    "output = merge([tower_1, tower_2, tower_3], mode='concat', concat_axis=1)\n",
    "\n",
    "predictions = Dense(150, activation='relu')(output)\n",
    "predictions = Dropout(0.5)(predictions)\n",
    "predictions = Dense(break_classes)(predictions)\n",
    "predictions = Activation('softmax')(predictions)\n",
    "\n",
    "model = Model(input=input_img, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flip_feature_target_pair(pair):\n",
    "    image_flipped = np.fliplr(pair[0])\n",
    "    steering_flipped = np.fliplr(pair[1])#-pair[1]\n",
    "    return [pair, [image_flipped, steering_flipped]]\n",
    "    \n",
    "def process_line(row, normalize_feature=True):\n",
    "    b,g,r = cv2.split(cv2.imread(row['path']))\n",
    "    img = np.array(cv2.merge([r,g,b]))\n",
    "    \n",
    "    if normalize_feature:\n",
    "        img = normalize(img)\n",
    "        \n",
    "    #steering = float(row['steering'])            \n",
    "    steering = row['steering']\n",
    "    return [img, steering]\n",
    "\n",
    "def generate_arrays_from_file(path, batch_size = 20, total=0):\n",
    "    while 1:\n",
    "        global X_train\n",
    "        global y_train\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        Xs = []\n",
    "        ys = []        \n",
    "        for i in range(len(X_train)):\n",
    "            if (len(Xs) == batch_size):\n",
    "                yield (np.array(Xs), np.array(ys))\n",
    "                Xs = []\n",
    "                ys = []\n",
    "\n",
    "            x, y = process_line({'path':X_train[i], 'steering':y_train[i]})\n",
    "            Xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "        yield (np.array(Xs), np.array(ys))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train records:  6428\n",
      "validation records:  1608\n"
     ]
    }
   ],
   "source": [
    "train_rows = len(X_train)\n",
    "validation_rows = len(X_validation)\n",
    "    \n",
    "print('train records: ', train_rows)\n",
    "print('validation records: ', validation_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6428/6428 [==============================] - 79s - loss: 0.5313 - acc: 0.8843 - val_loss: 0.5065 - val_acc: 0.8943\n",
      "Epoch 2/10\n",
      "6428/6428 [==============================] - 74s - loss: 0.4354 - acc: 0.8976 - val_loss: 0.4654 - val_acc: 0.8943\n",
      "Epoch 3/10\n",
      "6428/6428 [==============================] - 74s - loss: 0.4347 - acc: 0.8962 - val_loss: 0.4290 - val_acc: 0.8893\n",
      "Epoch 4/10\n",
      "6428/6428 [==============================] - 74s - loss: 0.4319 - acc: 0.8962 - val_loss: 0.4379 - val_acc: 0.8949\n",
      "Epoch 5/10\n",
      "6428/6428 [==============================] - 74s - loss: 0.4280 - acc: 0.8951 - val_loss: 0.4138 - val_acc: 0.8980\n",
      "Epoch 6/10\n",
      "6428/6428 [==============================] - 74s - loss: 0.4266 - acc: 0.8962 - val_loss: 0.4247 - val_acc: 0.8955\n",
      "Epoch 7/10\n",
      "6428/6428 [==============================] - 74s - loss: 0.4232 - acc: 0.8962 - val_loss: 0.4555 - val_acc: 0.8918\n",
      "Epoch 8/10\n",
      "6428/6428 [==============================] - 74s - loss: 0.4194 - acc: 0.8962 - val_loss: 0.3751 - val_acc: 0.9086\n",
      "Epoch 9/10\n",
      "6428/6428 [==============================] - 74s - loss: 0.4292 - acc: 0.8936 - val_loss: 0.4455 - val_acc: 0.8912\n",
      "Epoch 10/10\n",
      "6428/6428 [==============================] - 74s - loss: 0.4157 - acc: 0.8962 - val_loss: 0.4464 - val_acc: 0.8874\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "history = model.fit_generator(generate_arrays_from_file('train.csv',batch_size=100), samples_per_epoch=train_rows, nb_epoch=10, validation_data=generate_arrays_from_file('validation.csv', batch_size=1),nb_val_samples=validation_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "#    layer.trainable = True\n",
    "    \n",
    "#model.save('model1.h5')\n",
    "#model_json = model.to_json()\n",
    "#with open(\"model1.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from keras.models import load_model, model_from_json\n",
    "\n",
    "#json_file = open('model.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "#    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#json_file = open('model.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#model.load_weights(\"model1.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
