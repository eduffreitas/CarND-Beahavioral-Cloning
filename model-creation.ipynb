{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarND Behavioral Cloning Project\n",
    "\n",
    "This project is about training a neural network to drive a car on a simulator using data recorded from a humman driver.\n",
    "\n",
    "This notebook will be used to create the model to be used in driving the car on the simulator.\n",
    "\n",
    "The inputs come in three images right, central and left cameras.\n",
    "\n",
    "The first thing to do is to clean, then oganize the dataset, and save it to pickle file. for posterior use.\n",
    "\n",
    "The file driving_log.csv contains steering angles and the left, right and center images associated to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not(os.path.exists('train.csv') and os.path.exists('validation.csv')):\n",
    "\n",
    "    path_to_replace = \"C:\\\\Users\\\\eduardo\\\\Documents\\\\SelfDrivingCar\\\\beta-simulator-windows\\\\beta_simulator_windows\\\\data\"\n",
    "\n",
    "    def ReplaceWrongPath(value):\n",
    "        return value.replace(path_to_replace, \"\").replace(\"\\\\\", \"/\").replace(\" \", \"\")\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_train_left = []\n",
    "    y_train_left = []\n",
    "    X_train_right = []\n",
    "    y_train_right = []\n",
    "\n",
    "    with open('./data/driving_log.csv', 'r') as csv_file_in:\n",
    "\n",
    "        csv_reader = csv.DictReader(csv_file_in)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            steering = float(row['steering'])\n",
    "\n",
    "            #center image\n",
    "            path = './data/' + ReplaceWrongPath(row['center'].strip())        \n",
    "            X_train.append(path)\n",
    "            y_train.append(steering)\n",
    "            continue\n",
    "            \n",
    "            if steering == 0:\n",
    "                continue\n",
    "                \n",
    "            if steering < 0:\n",
    "                #left image\n",
    "                path = './data/' + ReplaceWrongPath(row['left'].strip())\n",
    "                steering_left = steering + 0.2\n",
    "\n",
    "                X_train_left.append(path)\n",
    "                y_train_left.append(steering_left)\n",
    "\n",
    "                #right image\n",
    "                path = './data/' + ReplaceWrongPath(row['right'].strip())\n",
    "                steering_right = steering - 0.2\n",
    "                steering_right = steering_right if steering_right > -1 else -1\n",
    "\n",
    "                X_train_right.append(path)\n",
    "                y_train_right.append(steering_right)\n",
    "            else:\n",
    "                #left image\n",
    "                path = './data/' + ReplaceWrongPath(row['left'].strip())\n",
    "                steering_left = steering + 0.2\n",
    "                steering_left = steering_left if steering_left < 1 else 1\n",
    "\n",
    "                X_train_left.append(path)\n",
    "                y_train_left.append(steering_left)\n",
    "\n",
    "                #right image\n",
    "                path = './data/' + ReplaceWrongPath(row['right'].strip())\n",
    "                steering_right = steering - 0.2\n",
    "\n",
    "                X_train_right.append(path)\n",
    "                y_train_right.append(steering_right)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    [X_train.append(item) for item in X_train_left]\n",
    "    [X_train.append(item) for item in X_train_right]\n",
    "    [y_train.append(item) for item in y_train_left]\n",
    "    [y_train.append(item) for item in y_train_right]\n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "    with open('train.csv', 'w') as csv_file_train:\n",
    "\n",
    "        fieldnames = ['path','steering']\n",
    "        writer = csv.DictWriter(csv_file_train, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for i in range(len(X_train)):\n",
    "            path, steering = X_train[i], y_train[i]\n",
    "            writer.writerow({'path': path, 'steering': steering})\n",
    "\n",
    "    with open('validation.csv', 'w') as csv_file_train:\n",
    "\n",
    "        fieldnames = ['path','steering']\n",
    "        writer = csv.DictWriter(csv_file_train, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for i in range(len(X_validation)):\n",
    "            path, steering = X_validation[i], y_validation[i]\n",
    "            writer.writerow({'path': path, 'steering': steering})\n",
    "\n",
    "    print(\"processing done\")\n",
    "else:\n",
    "    print(\"files exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def turn_linear_to_logistic(steering, n_classes):\n",
    "    interval = 2/n_classes\n",
    "    classes = []\n",
    "    lower_bound = -1\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        upper_bound = lower_bound + interval if i < (n_classes-1) else 1\n",
    "        classes.append(1 if steering > lower_bound and steering < upper_bound else 0)\n",
    "        lower_bound += interval\n",
    "        \n",
    "    return np.array(classes)\n",
    "    \n",
    "    \n",
    "break_classes = 21\n",
    "X_train_left = None\n",
    "y_train_left = None\n",
    "X_train_right = None\n",
    "y_train_right = None\n",
    "\n",
    "X_train= []\n",
    "y_train = []\n",
    "\n",
    "with open('train.csv', 'r') as csv_file_train:\n",
    "    \n",
    "    csv_reader = csv.DictReader(csv_file_train)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        X_train.append(row['path'])\n",
    "        y_train.append(float(row['steering']))\n",
    "        \n",
    "\n",
    "X_validation = []\n",
    "y_validation = []\n",
    "\n",
    "with open('validation.csv', 'r') as csv_file_val:\n",
    "    \n",
    "    csv_reader = csv.DictReader(csv_file_val)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        X_validation.append(row['path'])\n",
    "        y_validation.append(float(row['steering']))\n",
    "        \n",
    "print('Loading done')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAGHCAYAAAB8hmJnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79c65146d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins=70)\n",
    "plt.title(\"Training data\")\n",
    "plt.xlabel(\"Angles\")\n",
    "plt.ylabel(\"# of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(image_data):\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    img_min = 0\n",
    "    img_max = 255\n",
    "    return a + ( ( (image_data - img_min)*(b - a) )/( img_max - img_min ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "#### VGG with drop out, batch normalition\n",
    "\n",
    "#### 20 EPOCHS Adam optimizer linear regression\n",
    "\n",
    "#### Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda, Dense, Activation, Flatten, Input, Dropout, Convolution2D, MaxPooling2D, Cropping2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def get_model():\n",
    "    input_tensor = Input(shape=(160, 320, 3))\n",
    "    croped_input_img = Cropping2D(cropping=((60, 20), (0, 0)))(input_tensor)\n",
    "    croped_input_img = Lambda(lambda x: (x / 255.0) - 0.5)(croped_input_img)\n",
    "    base_model = VGG16(input_tensor=croped_input_img, weights='imagenet', include_top=False)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    top_model = base_model.output\n",
    "    top_model = Flatten()(top_model)\n",
    "\n",
    "    top_model = Dense(1024)(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Activation('relu')(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "\n",
    "    top_model = Dense(100)(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Activation('relu')(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "\n",
    "    top_model = Dense(50)(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Activation('relu')(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "\n",
    "    top_model = Dense(10)(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Activation('relu')(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "\n",
    "    predictions = Dense(1)(top_model)\n",
    "\n",
    "    model = Model(input=input_tensor, output=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from keras.layers import merge, ZeroPadding2D, Cropping2D, Convolution2D, MaxPooling2D, Input, Lambda, Flatten, Dense, Activation, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def AddConvLayer(features, kernel, input_layer):\n",
    "    complex_layer = ZeroPadding2D((1,1))(input_layer)\n",
    "    complex_layer = Convolution2D(features, kernel[0], kernel[1], activation='relu')(complex_layer)\n",
    "    complex_layer = Dropout(0.5)(complex_layer)\n",
    "    complex_layer = ZeroPadding2D((1,1))(complex_layer)\n",
    "    complex_layer = Convolution2D(features, kernel[0], kernel[1], activation='relu')(complex_layer)\n",
    "    complex_layer = Dropout(0.5)(complex_layer)\n",
    "    complex_layer = MaxPooling2D((2,2), strides=(2,2))(complex_layer)\n",
    "    return complex_layer\n",
    "\n",
    "def AddDenseLayer(neurons, depth, layer):\n",
    "    for i in range(depth):\n",
    "        layer = Dense(neurons, activation='relu')(layer)\n",
    "        layer = Dropout(0.5)(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "input_img = Input(shape=(160, 320, 3))\n",
    "croped_input_img = Cropping2D(cropping=((60, 20), (0, 0)))(input_img)\n",
    "croped_input_img = Lambda(lambda x: (x / 255.0) - 0.5)(croped_input_img)\n",
    "\n",
    "#tower_1 = AddConvLayer(6, (3, 2), croped_input_img)\n",
    "#tower_1 = AddConvLayer(6, (3, 2), tower_1)\n",
    "#tower_1 = AddConvLayer(6, (3, 2), tower_1)\n",
    "#tower_1 = AddConvLayer(16, (3, 2), tower_1)\n",
    "#tower_1 = AddConvLayer(16, (3, 2), tower_1)\n",
    "#tower_1 = AddConvLayer(16, (3, 2), tower_1)\n",
    "#tower_1 = Flatten()(tower_1)\n",
    "#tower_1 = AddDenseLayer(1024, 2, tower_1)\n",
    "\n",
    "tower_2_1 = AddConvLayer(32, (5, 5), croped_input_img)\n",
    "\n",
    "tower_2_1_1 = AddConvLayer(64, (5, 5), tower_2_1)\n",
    "\n",
    "tower_2_1_1_1 = AddConvLayer(128, (5, 5), tower_2_1_1)\n",
    "tower_2_1_1_2 = AddConvLayer(256, (3, 3), tower_2_1_1_1)\n",
    "tower_2_1_1_3 = AddConvLayer(512, (3, 3), tower_2_1_1_2)\n",
    "tower_2_1_1_4 = Flatten()(tower_2_1_1_3)\n",
    "\n",
    "tower_2_1_2 = AddConvLayer(128, (5, 5), tower_2_1_1)\n",
    "tower_2_1_3 = AddConvLayer(256, (3, 3), tower_2_1_2)\n",
    "tower_2_1_4 = AddConvLayer(512, (3, 3), tower_2_1_3)\n",
    "tower_2_1_5 = Flatten()(tower_2_1_4)\n",
    "\n",
    "tower_2_2 = AddConvLayer(64, (5, 5), tower_2_1)\n",
    "tower_2_3 = AddConvLayer(128, (5, 5), tower_2_2)\n",
    "tower_2_4 = AddConvLayer(256, (3, 3), tower_2_3)\n",
    "tower_2_5 = AddConvLayer(512, (3, 3), tower_2_4)\n",
    "tower_2_6 = Flatten()(tower_2_5)\n",
    "\n",
    "tower_2_6 = merge([tower_2_6, tower_2_1_5, tower_2_1_1_4], mode='concat', concat_axis=1)\n",
    "\n",
    "output = AddDenseLayer(1024, 1, tower_2_6)\n",
    "output = AddDenseLayer(84, 1, output)\n",
    "output = AddDenseLayer(50, 1, output)\n",
    "\n",
    "#tower_3 = AddConvLayer(6, (5, 2), croped_input_img)\n",
    "#tower_3 = AddConvLayer(6, (5, 2), tower_3)\n",
    "#tower_3 = AddConvLayer(16, (5, 2), tower_3)\n",
    "#tower_3 = AddConvLayer(16, (5, 2), tower_3)\n",
    "#tower_3 = Flatten()(tower_3)\n",
    "#tower_3 = AddDenseLayer(1024, 2, tower_3)\n",
    "\n",
    "#output = merge([tower_1, tower_2, tower_3], mode='concat', concat_axis=1)\n",
    "\n",
    "predictions = Dense(56, activation='relu')(output)\n",
    "predictions = Dropout(0.5)(predictions)\n",
    "predictions = Dense(1, activation='tanh')(predictions)\n",
    "\n",
    "model = Model(input=input_img, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_line(row):\n",
    "    b,g,r = cv2.split(cv2.imread(row['path']))\n",
    "    img = np.array(cv2.merge([r,g,b]))\n",
    "        \n",
    "    #steering = float(row['steering'])            \n",
    "    steering = row['steering']\n",
    "    return [img, steering]\n",
    "\n",
    "def generate_arrays_from_file(path, batch_size = 20, flip=True):\n",
    "    while 1:\n",
    "        global X_train\n",
    "        global y_train\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        Xs = []\n",
    "        ys = []        \n",
    "        for i in range(len(X_train)):\n",
    "            if (len(Xs) == batch_size):\n",
    "                yield (np.array(Xs), np.array(ys))\n",
    "                Xs = []\n",
    "                ys = []\n",
    "                \n",
    "            x, y = process_line({'path':X_train[i], 'steering':y_train[i]})\n",
    "            Xs.append(x)\n",
    "            ys.append(y)\n",
    "            \n",
    "            if flip:\n",
    "                if (len(Xs) == batch_size):\n",
    "                    yield (np.array(Xs), np.array(ys))\n",
    "                    Xs = []\n",
    "                    ys = []\n",
    "                    \n",
    "                x_flipped = np.fliplr(x)\n",
    "                y_filpped = -y\n",
    "\n",
    "                Xs.append(x_flipped)\n",
    "                ys.append(y_filpped)\n",
    "\n",
    "        yield (np.array(Xs), np.array(ys))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train records:  9215\n",
      "validation records:  2304\n"
     ]
    }
   ],
   "source": [
    "train_rows = len(X_train)\n",
    "validation_rows = len(X_validation)\n",
    "    \n",
    "print('train records: ', train_rows)\n",
    "print('validation records: ', validation_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 cropping2d_1 False\n",
      "2 lambda_1 False\n",
      "3 block1_conv1 False\n",
      "4 block1_conv2 False\n",
      "5 block1_pool False\n",
      "6 block2_conv1 False\n",
      "7 block2_conv2 False\n",
      "8 block2_pool False\n",
      "9 block3_conv1 False\n",
      "10 block3_conv2 False\n",
      "11 block3_conv3 False\n",
      "12 block3_pool False\n",
      "13 block4_conv1 False\n",
      "14 block4_conv2 False\n",
      "15 block4_conv3 False\n",
      "16 block4_pool False\n",
      "17 block5_conv1 False\n",
      "18 block5_conv2 False\n",
      "19 block5_conv3 False\n",
      "20 block5_pool False\n",
      "21 flatten_1 True\n",
      "22 dense_1 True\n",
      "23 batchnormalization_1 True\n",
      "24 activation_1 True\n",
      "25 dropout_1 True\n",
      "26 dense_2 True\n",
      "27 batchnormalization_2 True\n",
      "28 activation_2 True\n",
      "29 dropout_2 True\n",
      "30 dense_3 True\n",
      "31 batchnormalization_3 True\n",
      "32 activation_3 True\n",
      "33 dropout_3 True\n",
      "34 dense_4 True\n",
      "35 batchnormalization_4 True\n",
      "36 activation_4 True\n",
      "37 dropout_4 True\n",
      "38 dense_5 True\n"
     ]
    }
   ],
   "source": [
    "for i, Layer in enumerate(model.layers):\n",
    "    if i > 2 and i < 8:\n",
    "        print(i, Layer.name, Layer.trainable)\n",
    "    else:\n",
    "        print(i, Layer.name, Layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18430/18430 [==============================] - 522s - loss: 0.1518 - val_loss: 0.0907\n",
      "Epoch 2/2\n",
      "18430/18430 [==============================] - 518s - loss: 0.0868 - val_loss: 0.0856\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "model = get_model()\n",
    "checkpoint = ModelCheckpoint(\"model.h5\",\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='auto')\n",
    "\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='mean_absolute_error', optimizer=optimizer)\n",
    "history = model.fit_generator(generate_arrays_from_file('train.csv',batch_size=10), samples_per_epoch=train_rows*2, nb_epoch=2, validation_data=generate_arrays_from_file('validation.csv', batch_size=10, flip=False),nb_val_samples=validation_rows, callback=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0746773752671\n",
      "Truth:  0.3113208 Pred:  0.0343605 Error:  0.276960320437 Loss:  0.175818847852\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.117477340146\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0883065862923\n",
      "Truth:  -0.08490566 Pred:  -0.00748997 Error:  -0.0774156881835 Loss:  0.0861284066706\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0719060596809\n",
      "Truth:  0.5849057 Pred:  0.143245 Error:  0.441660986455 Loss:  0.124728192077\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.109236458659\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0971873326674\n",
      "Truth:  0.06603774 Pred:  -0.000794325 Error:  0.0668320647329 Loss:  0.0941518058739\n",
      "Truth:  0.0 Pred:  -0.0285794 Error:  0.0285794436932 Loss:  0.0881906820393\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809076522638\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0747450886076\n",
      "Truth:  0.0 Pred:  -0.014237 Error:  0.0142369940877 Loss:  0.0704230818561\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0657811647146\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0617194872157\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0664597364814\n",
      "Truth:  0.03773585 Pred:  0.0443639 Error:  -0.00662809199729 Loss:  0.0631357562323\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0598546282587\n",
      "Truth:  -0.02830189 Pred:  -0.0129286 Error:  -0.015373318448 Loss:  0.0576305627681\n",
      "Truth:  0.0 Pred:  -0.00512712 Error:  0.00512712169439 Loss:  0.0551303989075\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0526605773541\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0504055228923\n",
      "Truth:  -0.05660377 Pred:  -0.0460338 Error:  -0.0105699629011 Loss:  0.0487457078927\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0468276525663\n",
      "Truth:  -0.2830189 Pred:  -0.0419015 Error:  -0.241117386066 Loss:  0.0543003346239\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0523186305539\n",
      "Truth:  0.0 Pred:  -0.00901523 Error:  0.00901523139328 Loss:  0.0507720805839\n",
      "Truth:  -0.990566 Pred:  -0.000794325 Error:  -0.989771675267 Loss:  0.0831513769523\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804061418783\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0811855542284\n",
      "Truth:  0.7735849 Pred:  -0.000794325 Error:  0.774379224733 Loss:  0.102847856432\n",
      "Truth:  0.1415094 Pred:  0.0551743 Error:  0.086335146119 Loss:  0.102347471271\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0993606140196\n",
      "Truth:  -0.3490566 Pred:  -0.021216 Error:  -0.327840578149 Loss:  0.105888612995\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.10296932721\n",
      "Truth:  -0.04716982 Pred:  -0.0361776 Error:  -0.0109922108842 Loss:  0.100483459201\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0978600609254\n",
      "Truth:  -0.09433963 Pred:  -0.0195506 Error:  -0.0747890140784 Loss:  0.0972684956216\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0948566413494\n",
      "Truth:  0.3962264 Pred:  -0.000794325 Error:  0.397020724733 Loss:  0.102226497042\n",
      "Truth:  0.1981132 Pred:  0.0157046 Error:  0.182408646426 Loss:  0.104135595837\n",
      "Truth:  0.3962264 Pred:  -0.000794325 Error:  0.397020724733 Loss:  0.110946877904\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.108443410786\n",
      "Truth:  0.0 Pred:  0.0650616 Error:  -0.0650616288185 Loss:  0.107479371187\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.105160131047\n",
      "Truth:  -0.05660377 Pred:  -0.00952823 Error:  -0.0470755391243 Loss:  0.103924288665\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.102168829417\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.100099961974\n",
      "Truth:  0.0 Pred:  0.0116191 Error:  -0.011619140394 Loss:  0.0983303455427\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0964178745465\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.094578960127\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0928094387044\n",
      "Truth:  -0.254717 Pred:  -0.000794325 Error:  -0.253922675267 Loss:  0.0957930171593\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0940657682061\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0924002067155\n",
      "Truth:  0.0 Pred:  -0.00141379 Error:  0.00141379376873 Loss:  0.0908039538568\n",
      "Truth:  0.0 Pred:  -0.0178307 Error:  0.0178306698799 Loss:  0.0895457937882\n",
      "Truth:  0.06603774 Pred:  -0.000794325 Error:  0.0668320647329 Loss:  0.0891608153296\n",
      "Truth:  0.1792453 Pred:  -0.000794325 Error:  0.180039624733 Loss:  0.090675462153\n",
      "Truth:  0.3207547 Pred:  -0.000794325 Error:  0.321549024733 Loss:  0.0944602746543\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0929495335266\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0914867524346\n",
      "Truth:  0.0 Pred:  -0.00245793 Error:  0.00245793000795 Loss:  0.0900956770842\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0887218101249\n",
      "Truth:  -0.1698113 Pred:  -0.000794325 Error:  -0.169016975267 Loss:  0.0899384035362\n",
      "Truth:  0.0 Pred:  -0.0074755 Error:  0.00747550139204 Loss:  0.0887076139519\n",
      "Truth:  0.0 Pred:  -0.00147117 Error:  0.00147116591688 Loss:  0.0874247250103\n",
      "Truth:  0.0 Pred:  -0.00679596 Error:  0.00679596001282 Loss:  0.0862561921842\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0850353083635\n",
      "Truth:  0.0 Pred:  0.000679791 Error:  -0.000679791264702 Loss:  0.0838472024888\n",
      "Truth:  0.0 Pred:  -0.000688954 Error:  0.000688953732606 Loss:  0.0826922268117\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815703377421\n",
      "Truth:  0.0 Pred:  -0.00591635 Error:  0.00591634912416 Loss:  0.0805479865446\n",
      "Truth:  0.0 Pred:  -0.0221801 Error:  0.022180147469 Loss:  0.0797697486902\n",
      "Truth:  -0.3490566 Pred:  -0.000794325 Error:  -0.348262275267 Loss:  0.0833025450925\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0829661236593\n",
      "Truth:  -0.08490566 Pred:  -0.00714564 Error:  -0.0777600153688 Loss:  0.0828993786812\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818600742009\n",
      "Truth:  0.0 Pred:  0.00145008 Error:  -0.00145007972606 Loss:  0.0808549492699\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798665464979\n",
      "Truth:  0.0 Pred:  0.0605862 Error:  -0.0605862215161 Loss:  0.0796314205835\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0793635491877\n",
      "Truth:  -0.02830189 Pred:  -0.00389795 Error:  -0.0244039425079 Loss:  0.0787092681558\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0777926217625\n",
      "Truth:  0.0 Pred:  -0.0221005 Error:  0.0221005380154 Loss:  0.0771450393934\n",
      "Truth:  0.0 Pred:  0.0269356 Error:  -0.0269355811179 Loss:  0.0765679191833\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.07570685561\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.07486514178\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0740421327017\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.073237211735\n",
      "Truth:  0.15 Pred:  -0.000794325 Error:  0.150794324733 Loss:  0.0740802238328\n",
      "Truth:  0.245283 Pred:  -0.000794325 Error:  0.246077324733 Loss:  0.0759296550252\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0751303430009\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.074347858598\n",
      "Truth:  0.6603773 Pred:  0.00240124 Error:  0.657976064952 Loss:  0.0804273190809\n",
      "Truth:  0.2735849 Pred:  -0.000794325 Error:  0.274379224733 Loss:  0.0824268232629\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081593838584\n",
      "Truth:  0.1603774 Pred:  -0.000794325 Error:  0.161171724733 Loss:  0.0823976556158\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0817544150123\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.08095282996\n",
      "Truth:  -0.4433962 Pred:  -0.0365503 Error:  -0.406845931469 Loss:  0.084147860367\n",
      "Truth:  -0.02830189 Pred:  -0.0123533 Error:  -0.0159486383118 Loss:  0.0834857319975\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0826906223123\n",
      "Truth:  -0.1132075 Pred:  -0.00775163 Error:  -0.10545587264 Loss:  0.0829074342202\n",
      "Truth:  0.05660377 Pred:  0.00393836 Error:  0.0526654131199 Loss:  0.0826221321343\n",
      "Truth:  0.0 Pred:  -0.00790701 Error:  0.00790701154619 Loss:  0.0819238599793\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811726605789\n",
      "Truth:  -0.09433963 Pred:  -0.000794325 Error:  -0.0935453052671 Loss:  0.0812861710806\n",
      "Truth:  0.0 Pred:  -0.00919915 Error:  0.00919914990664 Loss:  0.0806308345245\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799115866885\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792051825639\n",
      "Truth:  0.0 Pred:  -0.000561924 Error:  0.00056192377815 Loss:  0.0785092245215\n",
      "Truth:  -0.06603774 Pred:  -0.000794325 Error:  -0.0652434152671 Loss:  0.0783928577737\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0783743635733\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0777055701351\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0770482090632\n",
      "Truth:  -0.08490566 Pred:  -0.0102879 Error:  -0.0746177353303 Loss:  0.0770276118282\n",
      "Truth:  0.254717 Pred:  -0.000794325 Error:  0.255511324733 Loss:  0.0785274749619\n",
      "Truth:  0.0 Pred:  -0.00189968 Error:  0.00189967942424 Loss:  0.0778889099991\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0776415978894\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0781716153226\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0775425316592\n",
      "Truth:  0.0 Pred:  0.111242 Error:  -0.111241683364 Loss:  0.0778142990117\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0771981392175\n",
      "Truth:  -0.05660377 Pred:  -0.000794325 Error:  -0.0558094452671 Loss:  0.0770283876782\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.076428119466\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0758372304447\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0752555024934\n",
      "Truth:  0.0 Pred:  0.000910588 Error:  -0.000910588016268 Loss:  0.0746836185359\n",
      "Truth:  0.2169811 Pred:  -0.000794325 Error:  0.217775424733 Loss:  0.0757759224\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0752078799934\n",
      "Truth:  0.0 Pred:  -0.0123231 Error:  0.0123231392354 Loss:  0.0747350623937\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0744530210719\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.073907401099\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0733698049493\n",
      "Truth:  -0.09433963 Pred:  -0.0335529 Error:  -0.0607867784721 Loss:  0.0732779580407\n",
      "Truth:  0.0754717 Pred:  0.0033197 Error:  0.0721520041752 Loss:  0.0732697989547\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0727483926653\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0722344350372\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0717277675883\n",
      "Truth:  0.0 Pred:  -0.045319 Error:  0.0453189909458 Loss:  0.071541790288\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0719046856337\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.071410863683\n",
      "Truth:  -0.1037736 Pred:  -0.0514549 Error:  -0.0523186647771 Loss:  0.0712791933457\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0707964202731\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0703202155415\n",
      "Truth:  -0.2075472 Pred:  -0.0374946 Error:  -0.17005259273 Loss:  0.0709940829549\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.070522943638\n",
      "Truth:  -0.06603774 Pred:  -0.00833045 Error:  -0.057707293332 Loss:  0.0704375059693\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0699762928485\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0695211483214\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0694419126771\n",
      "Truth:  0.4811321 Pred:  -0.000534804 Error:  0.481666903665 Loss:  0.0721186983328\n",
      "Truth:  0.0 Pred:  0.00195635 Error:  -0.00195634784177 Loss:  0.0716660380071\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0712117321528\n",
      "Truth:  0.1792453 Pred:  0.15159 Error:  0.0276555189541 Loss:  0.0709343040432\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0704903801235\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0700520401525\n",
      "Truth:  0.0 Pred:  0.0818096 Error:  -0.0818096101284 Loss:  0.0701255249649\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.069694896392\n",
      "Truth:  -0.2075472 Pred:  -0.000794325 Error:  -0.206752875267 Loss:  0.0705409332986\n",
      "Truth:  0.0 Pred:  -0.00710415 Error:  0.0071041486226 Loss:  0.0701517505706\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0697288394374\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0693110544998\n",
      "Truth:  -0.06603774 Pred:  -0.0230014 Error:  -0.0430363075812 Loss:  0.0691527728919\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.068743440867\n",
      "Truth:  0.0 Pred:  -0.0342762 Error:  0.0342761650681 Loss:  0.068538278511\n",
      "Truth:  0.0 Pred:  -0.00871548 Error:  0.00871548429132 Loss:  0.0681842974801\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0677878858757\n",
      "Truth:  -0.4528302 Pred:  -0.0583573 Error:  -0.394472927703 Loss:  0.0696983247168\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0692977200658\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0689017466823\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0685103247171\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0681233761458\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0677408247173\n",
      "Truth:  0.0 Pred:  0.0593181 Error:  -0.0593181438744 Loss:  0.0676932389498\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0673174023531\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0669457650479\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0665782570462\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0662148099063\n",
      "Truth:  0.0 Pred:  -0.0190447 Error:  0.0190446600318 Loss:  0.0659556332587\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0655995605345\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.065247358166\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.065714873661\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0653658384517\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0650205362393\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0646789074547\n",
      "Truth:  -0.09433963 Pred:  -0.0156417 Error:  -0.0786979015839 Loss:  0.0647530820268\n",
      "Truth:  -0.254717 Pred:  -0.000794325 Error:  -0.253922675267 Loss:  0.0657487114649\n",
      "Truth:  0.2735849 Pred:  0.0116472 Error:  0.261937651359 Loss:  0.0667758786895\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0664322247626\n",
      "Truth:  -0.009433962 Pred:  -0.00436541 Error:  -0.00506854808463 Loss:  0.0661142782513\n",
      "Truth:  0.5943396 Pred:  -0.000794325 Error:  0.595133924733 Loss:  0.0688411836456\n",
      "Truth:  -0.5 Pred:  -0.0535915 Error:  -0.446408517659 Loss:  0.0707774263841\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.070420369743\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0700669380424\n",
      "Truth:  0.0 Pred:  -0.0325059 Error:  0.0325058586895 Loss:  0.0698772356215\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0695300853155\n",
      "Truth:  -0.4245283 Pred:  -0.0572839 Error:  -0.367244354618 Loss:  0.071018656662\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0707162170106\n",
      "Truth:  -0.08490566 Pred:  -0.0164756 Error:  -0.0684300924058 Loss:  0.0707048995621\n",
      "Truth:  -0.1132075 Pred:  -0.000794325 Error:  -0.112413175267 Loss:  0.0709103590483\n",
      "Truth:  0.0 Pred:  -0.0324939 Error:  0.032493904233 Loss:  0.0707220430933\n",
      "Truth:  0.0 Pred:  0.0182547 Error:  -0.0182547345757 Loss:  0.070466105003\n",
      "Truth:  -0.1037736 Pred:  -0.000794325 Error:  -0.102979275267 Loss:  0.0706239359266\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0702865948097\n",
      "Truth:  -0.01886792 Pred:  -0.0291435 Error:  0.0102755512708 Loss:  0.0699980801773\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0696669617302\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0693389967922\n",
      "Truth:  0.0 Pred:  -0.00375182 Error:  0.00375181622803 Loss:  0.0690281570738\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0687062993741\n",
      "Truth:  0.4056604 Pred:  -0.000794325 Error:  0.406454724733 Loss:  0.0702919727326\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0699672173681\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0696454829838\n",
      "Truth:  0.0 Pred:  -0.0591676 Error:  0.0591676346958 Loss:  0.0695969744269\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0692799115251\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0689657574572\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0686544723763\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0685103226167\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0682039153865\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0679002685817\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0679306591947\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0676309434158\n",
      "Truth:  -0.1132075 Pred:  -0.0285198 Error:  -0.0846877037925 Loss:  0.0677067512397\n",
      "Truth:  0.0 Pred:  -0.0175395 Error:  0.0175394788384 Loss:  0.0674847721583\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.067190981641\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0668997682335\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0670642579999\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0667761278552\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0664904923439\n",
      "Truth:  0.0 Pred:  -0.009046 Error:  0.00904599763453 Loss:  0.0662428867632\n",
      "Truth:  0.1037736 Pred:  0.0146479 Error:  0.0891257194309 Loss:  0.0663410963455\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0660609819369\n",
      "Truth:  -0.05660377 Pred:  -0.0374762 Error:  -0.0191276066425 Loss:  0.0658612654463\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0655855580704\n",
      "Truth:  -0.1603774 Pred:  -0.0148014 Error:  -0.145575955514 Loss:  0.0659230702959\n",
      "Truth:  0.0 Pred:  0.147156 Error:  -0.147156208754 Loss:  0.0662643860037\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0659904526929\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0657188021598\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0654494059879\n",
      "Truth:  -0.5188679 Pred:  -0.0385416 Error:  -0.480326262639 Loss:  0.0671637731641\n",
      "Truth:  -0.1415094 Pred:  -0.0516417 Error:  -0.0898676936227 Loss:  0.0672572049355\n",
      "Truth:  -0.02830189 Pred:  -0.0180437 Error:  -0.0102582191967 Loss:  0.067023602535\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0667532789521\n",
      "Truth:  0.0 Pred:  -0.0332304 Error:  0.0332303531468 Loss:  0.066617006896\n",
      "Truth:  0.06603774 Pred:  0.00188392 Error:  0.0641538183209 Loss:  0.0666070344726\n",
      "Truth:  0.0 Pred:  0.000615558 Error:  -0.000615558179561 Loss:  0.0663409398101\n",
      "Truth:  0.5188679 Pred:  0.142195 Error:  0.376672764645 Loss:  0.0675872523597\n",
      "Truth:  0.0 Pred:  -0.0359764 Error:  0.0359763912857 Loss:  0.0674608089154\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0674207184206\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0671563279695\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0669250367019\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0666646795682\n",
      "Truth:  0.0 Pred:  -0.00235985 Error:  0.00235985172912 Loss:  0.0664125037727\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0667089538546\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0664524766985\n",
      "Truth:  0.0 Pred:  -0.0108382 Error:  0.0108381640166 Loss:  0.066236917347\n",
      "Truth:  0.2735849 Pred:  0.0123302 Error:  0.261254733004 Loss:  0.0669898818862\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0667352835895\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0664826362375\n",
      "Truth:  -0.9150943 Pred:  -0.000794325 Error:  -0.914299975267 Loss:  0.0697185802796\n",
      "Truth:  -0.08490566 Pred:  -0.00436143 Error:  -0.0805442274886 Loss:  0.0697597424363\n",
      "Truth:  -0.1226415 Pred:  -0.000794325 Error:  -0.121847175267 Loss:  0.0699570433182\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0698324564577\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0695729146091\n",
      "Truth:  0.0 Pred:  0.0766412 Error:  -0.0766412466764 Loss:  0.0695993877629\n",
      "Truth:  0.990566 Pred:  0.0317423 Error:  0.958823728964 Loss:  0.072917389036\n",
      "Truth:  0.0 Pred:  -0.00188401 Error:  0.00188400526531 Loss:  0.0726533244123\n",
      "Truth:  -0.3018868 Pred:  -0.0255489 Error:  -0.276337917218 Loss:  0.0734077117931\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0731397657154\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0728737898294\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0727825457082\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0725198149747\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0722589950102\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.0725469614222\n",
      "Truth:  0.1792453 Pred:  -0.000794325 Error:  0.180039624733 Loss:  0.0729350215786\n",
      "Truth:  -0.1226415 Pred:  -0.0398419 Error:  -0.0827995835879 Loss:  0.0729705056146\n",
      "Truth:  0.0 Pred:  -0.0646064 Error:  0.0646063685417 Loss:  0.0729405266287\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0726828616219\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.0724941761525\n",
      "Truth:  0.0 Pred:  0.112319 Error:  -0.112318590283 Loss:  0.0726353974792\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0723815420985\n",
      "Truth:  -0.1320755 Pred:  -0.00105345 Error:  -0.13102205461 Loss:  0.0725880227764\n",
      "Truth:  0.02830189 Pred:  -0.000794325 Error:  0.0290962147329 Loss:  0.0724354199411\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0721849266012\n",
      "Truth:  -0.1981132 Pred:  -0.0204902 Error:  -0.177623037925 Loss:  0.0725523067801\n",
      "Truth:  0.1226415 Pred:  0.0399589 Error:  0.0826826169231 Loss:  0.0725874814681\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0728287141437\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0728405669389\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0725929853505\n",
      "Truth:  0.5660377 Pred:  0.168106 Error:  0.397932067933 Loss:  0.0737071602909\n",
      "Truth:  0.0 Pred:  0.0254881 Error:  -0.0254881195724 Loss:  0.073542590186\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0732951471063\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0730493816067\n",
      "Truth:  0.0 Pred:  -0.0230158 Error:  0.0230157896876 Loss:  0.0728803492016\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0726376353145\n",
      "Truth:  -0.08490566 Pred:  -0.0122006 Error:  -0.0727050762962 Loss:  0.0726378616265\n",
      "Truth:  0.0 Pred:  -0.00176167 Error:  0.00176167278551 Loss:  0.0724008175166\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0721621292074\n",
      "Truth:  -0.5471698 Pred:  -0.033119 Error:  -0.514050844209 Loss:  0.073630198028\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0733890196396\n",
      "Truth:  0.0 Pred:  -0.0288287 Error:  0.0288286712021 Loss:  0.0732419557833\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0730036412075\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0727668893502\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0725316848907\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0722980127078\n",
      "Truth:  0.0 Pred:  0.0370671 Error:  -0.0370671488345 Loss:  0.0721836267861\n",
      "Truth:  -0.08490566 Pred:  -0.0225509 Error:  -0.062354721349 Loss:  0.0721518180306\n",
      "Truth:  0.0 Pred:  -0.0222145 Error:  0.0222144890577 Loss:  0.0719907298727\n",
      "Truth:  -0.1037736 Pred:  -0.0416066 Error:  -0.0621670172988 Loss:  0.0719591423724\n",
      "Truth:  -0.3207547 Pred:  -0.0195411 Error:  -0.301213626409 Loss:  0.0726939323854\n",
      "Truth:  0.0 Pred:  -0.00415815 Error:  0.00415815366432 Loss:  0.0724749682361\n",
      "Truth:  0.1603774 Pred:  -0.000794325 Error:  0.161171724733 Loss:  0.0727574419829\n",
      "Truth:  0.0 Pred:  -0.00503444 Error:  0.00503444299102 Loss:  0.0725424483353\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0723153973112\n",
      "Truth:  0.0 Pred:  -0.0395669 Error:  0.0395668521523 Loss:  0.0722120895978\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0719875054316\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0717643293165\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0715425480522\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0713221486026\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0711031180937\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0708854438108\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0706691131964\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0704541138473\n",
      "Truth:  -0.1792453 Pred:  -0.000794325 Error:  -0.178450975267 Loss:  0.0707853925633\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0707156028146\n",
      "Truth:  0.09433963 Pred:  -0.000794325 Error:  0.0951339547329 Loss:  0.0707900490095\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0705772960481\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0703658324987\n",
      "Truth:  0.1132075 Pred:  -0.000794325 Error:  0.114001824733 Loss:  0.0704976632909\n",
      "Truth:  0.009433962 Pred:  0.00518871 Error:  0.00424525613471 Loss:  0.0702981078477\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0700893877783\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0698819175296\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0696756859094\n",
      "Truth:  0.01886792 Pred:  -0.044978 Error:  0.063845886696 Loss:  0.0696583353165\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0694539910714\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0692508559639\n",
      "Truth:  0.25 Pred:  -0.000794325 Error:  0.250794324733 Loss:  0.0697863824204\n",
      "Truth:  -0.009433962 Pred:  -0.0356161 Error:  0.0261820968562 Loss:  0.0696581345217\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0694561878654\n",
      "Truth:  0.0 Pred:  0.0169608 Error:  -0.0169608183205 Loss:  0.0693026926329\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0691029597818\n",
      "Truth:  0.0 Pred:  0.0103053 Error:  -0.0103052509949 Loss:  0.0689320362098\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0687345355968\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0685381766059\n",
      "Truth:  0.0 Pred:  -0.00880764 Error:  0.00880764052272 Loss:  0.0683660424961\n",
      "Truth:  0.0 Pred:  -0.0173593 Error:  0.0173593107611 Loss:  0.0682194714279\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0680262761652\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0678341848754\n",
      "Truth:  0.06603774 Pred:  -0.000794325 Error:  0.0668320647329 Loss:  0.0678313298322\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0678552920337\n",
      "Truth:  0.2641509 Pred:  -0.000794325 Error:  0.264945224733 Loss:  0.0684136204549\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0682226054952\n",
      "Truth:  0.01886792 Pred:  0.00823848 Error:  0.0106294386423 Loss:  0.0680603712224\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0678714216536\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0676835306258\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0678919669222\n",
      "Truth:  -0.2075472 Pred:  -0.0345427 Error:  -0.173004479235 Loss:  0.0681847594356\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0679975637837\n",
      "Truth:  1.0 Pred:  -0.000794325 Error:  1.00079432473 Loss:  0.0705814883292\n",
      "Truth:  0.1509434 Pred:  0.00514365 Error:  0.145799750124 Loss:  0.0707892735828\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0705964500323\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0704046859518\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0702139726334\n",
      "Truth:  0.0 Pred:  -0.0126832 Error:  0.012683160603 Loss:  0.0700567846223\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0698680585736\n",
      "Truth:  -0.1509434 Pred:  -0.000794325 Error:  -0.150149075267 Loss:  0.0700862135103\n",
      "Truth:  -0.1981132 Pred:  -0.0215674 Error:  -0.176545764065 Loss:  0.0703747217774\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0701866666502\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0701987709861\n",
      "Truth:  0.2169811 Pred:  0.0222607 Error:  0.194720374502 Loss:  0.0705335064794\n",
      "Truth:  0.0 Pred:  -0.00705696 Error:  0.00705695850775 Loss:  0.0703633280666\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0702025391861\n",
      "Truth:  0.2924528 Pred:  -0.000794325 Error:  0.293247124733 Loss:  0.0707973247475\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.070611146556\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0704509798191\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0702667029538\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0700833985257\n",
      "Truth:  0.0 Pred:  -0.0137935 Error:  0.0137934517115 Loss:  0.0699352670867\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0697537947971\n",
      "Truth:  0.0 Pred:  0.00370341 Error:  -0.0037034091074 Loss:  0.0695808880283\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0694998156698\n",
      "Truth:  0.0 Pred:  -0.0209038 Error:  0.0209037512541 Loss:  0.0693732634187\n",
      "Truth:  0.0 Pred:  -0.00677306 Error:  0.00677306158468 Loss:  0.0692106654919\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0690334210858\n",
      "Truth:  -0.1603774 Pred:  -0.0616496 Error:  -0.0987277682911 Loss:  0.0691101506651\n",
      "Truth:  0.0 Pred:  -0.026163 Error:  0.0261629540473 Loss:  0.068999462014\n",
      "Truth:  -0.2264151 Pred:  -0.000794325 Error:  -0.225620775267 Loss:  0.069402087498\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0692261701576\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0690511526501\n",
      "Truth:  -0.7924529 Pred:  -0.000794325 Error:  -0.791658575267 Loss:  0.0708945389323\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.070716166886\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0706823646724\n",
      "Truth:  0.6037736 Pred:  0.0598089 Error:  0.543964701283 Loss:  0.071880547803\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0717923179481\n",
      "Truth:  -0.02830189 Pred:  -0.0277261 Error:  -0.000575798555508 Loss:  0.0716129312494\n",
      "Truth:  0.0 Pred:  -0.0617542 Error:  0.0617541559041 Loss:  0.0715881604571\n",
      "Truth:  -0.3490566 Pred:  -0.000794325 Error:  -0.348262275267 Loss:  0.0722815792912\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0721028611548\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0719250343807\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0717480923169\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0715720283775\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0714863093104\n",
      "Truth:  -0.25 Pred:  -0.000794325 Error:  -0.249205675267 Loss:  0.0719251225596\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0717499235502\n",
      "Truth:  0.1603774 Pred:  -0.000794325 Error:  0.161171724733 Loss:  0.0719696331354\n",
      "Truth:  0.2735849 Pred:  -0.000794325 Error:  0.274379224733 Loss:  0.0724657350756\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0723788788169\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0725494272216\n",
      "Truth:  0.06603774 Pred:  -0.000794325 Error:  0.0668320647329 Loss:  0.072535516364\n",
      "Truth:  -0.4811321 Pred:  -0.0462269 Error:  -0.434905166401 Loss:  0.0734150543495\n",
      "Truth:  -0.03773585 Pred:  -0.0579789 Error:  0.0202430967156 Loss:  0.0732863086894\n",
      "Truth:  0.0 Pred:  -0.00834894 Error:  0.00834893714637 Loss:  0.0731294551349\n",
      "Truth:  0.0 Pred:  -0.017893 Error:  0.0178930088878 Loss:  0.0729963552644\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0729361816814\n",
      "Truth:  0.1792453 Pred:  -0.000794325 Error:  0.180039624733 Loss:  0.0731930244705\n",
      "Truth:  -0.2641509 Pred:  -0.000794325 Error:  -0.263356575267 Loss:  0.0736479611949\n",
      "Truth:  0.0 Pred:  -0.0189971 Error:  0.0189971048385 Loss:  0.0735175295568\n",
      "Truth:  0.0 Pred:  -0.0166095 Error:  0.016609467566 Loss:  0.0733820341711\n",
      "Truth:  -0.7830189 Pred:  -0.0446589 Error:  -0.738360049122 Loss:  0.0749615543967\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0747858026676\n",
      "Truth:  -0.04716982 Pred:  -0.000794325 Error:  -0.0463754952671 Loss:  0.0747186388203\n",
      "Truth:  -0.3207547 Pred:  -0.046845 Error:  -0.273909673686 Loss:  0.0751884289969\n",
      "Truth:  -0.02830189 Pred:  -0.0141667 Error:  -0.0141352135607 Loss:  0.0750447743723\n",
      "Truth:  -0.254717 Pred:  -0.000794325 Error:  -0.253922675267 Loss:  0.0754646755481\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0752898035322\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0751157486752\n",
      "Truth:  -0.4622642 Pred:  -0.00314287 Error:  -0.45912132927 Loss:  0.0760108665787\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0758359443883\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0756618339019\n",
      "Truth:  0.0 Pred:  0.000531029 Error:  -0.000531028781552 Loss:  0.0754879200011\n",
      "Truth:  0.245283 Pred:  -0.000794325 Error:  0.246077324733 Loss:  0.0758818909128\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0757088780875\n",
      "Truth:  -0.09433963 Pred:  -0.00335911 Error:  -0.0909805173443 Loss:  0.0757439853041\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0755720824129\n",
      "Truth:  0.0 Pred:  -0.0111016 Error:  0.0111015513539 Loss:  0.0754245525936\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0755772447674\n",
      "Truth:  -0.3490566 Pred:  -0.00709223 Error:  -0.341964369978 Loss:  0.0761840491528\n",
      "Truth:  0.0 Pred:  0.0021215 Error:  -0.00212150206789 Loss:  0.0760157251822\n",
      "Truth:  -0.08490566 Pred:  -0.018413 Error:  -0.0664926862682 Loss:  0.0759941309897\n",
      "Truth:  -0.8773585 Pred:  -0.0118832 Error:  -0.865475310098 Loss:  0.0777802875035\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0778407562105\n",
      "Truth:  0.6500001 Pred:  -0.000794325 Error:  0.650794424733 Loss:  0.0791311924009\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078955154496\n",
      "Truth:  0.0 Pred:  0.0104814 Error:  -0.0104813845828 Loss:  0.0788016258639\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0787079791064\n",
      "Truth:  0.0 Pred:  -0.0164942 Error:  0.0164942070842 Loss:  0.0785691090796\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0783958912971\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0782234433714\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0780517601815\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0781104242624\n",
      "Truth:  0.0 Pred:  -0.00849474 Error:  0.00849473848939 Loss:  0.0779567472518\n",
      "Truth:  -0.1132075 Pred:  -0.000794325 Error:  -0.112413175267 Loss:  0.0780326424677\n",
      "Truth:  0.1886793 Pred:  -0.000794325 Error:  0.189473624733 Loss:  0.0782775677035\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0782317793856\n",
      "Truth:  -0.3773585 Pred:  -0.0243442 Error:  -0.353014322083 Loss:  0.0788330540961\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786626638573\n",
      "Truth:  0.0 Pred:  -0.0390183 Error:  0.0390182882547 Loss:  0.0785762926686\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078407201434\n",
      "Truth:  0.6320755 Pred:  0.120201 Error:  0.511874322105 Loss:  0.0793474771838\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0791774487153\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.0790489061581\n",
      "Truth:  0.0 Pred:  -0.0301658 Error:  0.0301657766104 Loss:  0.0789435545858\n",
      "Truth:  -0.1415094 Pred:  -0.000794325 Error:  -0.140715075267 Loss:  0.0790763965657\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0791715884717\n",
      "Truth:  0.1981132 Pred:  -0.000794325 Error:  0.198907524733 Loss:  0.0794279823395\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792599617036\n",
      "Truth:  -0.04716982 Pred:  -0.000794325 Error:  -0.0463754952671 Loss:  0.0791898455704\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0790230465899\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0788569558854\n",
      "Truth:  0.6981132 Pred:  0.0401542 Error:  0.657959003678 Loss:  0.0800838670036\n",
      "Truth:  -0.05660377 Pred:  -0.000794325 Error:  -0.0558094452671 Loss:  0.080032546873\n",
      "Truth:  -0.06603774 Pred:  -0.000794325 Error:  -0.0652434152671 Loss:  0.0800013461735\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798345945494\n",
      "Truth:  -0.2264151 Pred:  -0.021572 Error:  -0.20484308382 Loss:  0.080097217426\n",
      "Truth:  0.4056604 Pred:  -0.000794325 Error:  0.406454724733 Loss:  0.0807814050723\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806140680842\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804474297891\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802814858202\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801162318471\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079951663575\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797877767451\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796245671335\n",
      "Truth:  0.0 Pred:  -0.0214923 Error:  0.0214922688901 Loss:  0.0795047067248\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793427512063\n",
      "Truth:  -0.2075472 Pred:  -0.000794325 Error:  -0.206752875267 Loss:  0.0796043736376\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794428776358\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792820421493\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0791218631341\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0789623365793\n",
      "Truth:  0.1698113 Pred:  -0.000729647 Error:  0.170540946708 Loss:  0.0791484719658\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0789895386043\n",
      "Truth:  -0.009433962 Pred:  -0.0245895 Error:  0.0151555151069 Loss:  0.0788603199332\n",
      "Truth:  -0.6037736 Pred:  -0.0387742 Error:  -0.564999418843 Loss:  0.0798424191229\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796830479649\n",
      "Truth:  -0.6509434 Pred:  -0.000827931 Error:  -0.65011546855 Loss:  0.0808307993141\n",
      "Truth:  0.0 Pred:  -0.00511816 Error:  0.00511815911159 Loss:  0.0806787659001\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805186768396\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803592281354\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.0805393606635\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803805060103\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802222829859\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0800834060092\n",
      "Truth:  -0.1509434 Pred:  -0.000794325 Error:  -0.150149075267 Loss:  0.0802221499087\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800651779222\n",
      "Truth:  -0.3679245 Pred:  -0.00296563 Error:  -0.364958868571 Loss:  0.0806270984166\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804699472873\n",
      "Truth:  0.6132075 Pred:  0.00397596 Error:  0.609231539574 Loss:  0.0815087716336\n",
      "Truth:  0.2924528 Pred:  0.0561344 Error:  0.236318371171 Loss:  0.081812319868\n",
      "Truth:  -1.0 Pred:  -0.0200289 Error:  -0.979971125722 Loss:  0.0835699691945\n",
      "Truth:  -0.2075472 Pred:  -0.00880044 Error:  -0.198746759532 Loss:  0.0837949238632\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0836331293229\n",
      "Truth:  0.1981132 Pred:  -0.000869791 Error:  0.198982991198 Loss:  0.0838575453966\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0836962575895\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0835355949289\n",
      "Truth:  0.0 Pred:  -0.00729681 Error:  0.00729681411758 Loss:  0.0833881311363\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0833713150053\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0832122071242\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0830537111965\n",
      "Truth:  0.4622642 Pred:  0.0698411 Error:  0.392423060981 Loss:  0.0836475103324\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.083503817089\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0833456727441\n",
      "Truth:  -0.6509434 Pred:  -0.0283985 Error:  -0.622544912283 Loss:  0.0843746789264\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0842154782518\n",
      "Truth:  0.0 Pred:  -0.00256387 Error:  0.00256386701949 Loss:  0.0840602470517\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0839022471991\n",
      "Truth:  0.0 Pred:  -0.000129951 Error:  0.00012995058205 Loss:  0.0837435875464\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.083586783647\n",
      "Truth:  0.08490566 Pred:  -0.000794325 Error:  0.0856999847329 Loss:  0.0835907708188\n",
      "Truth:  0.0 Pred:  -0.0325203 Error:  0.0325203388929 Loss:  0.0834945929809\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.083353888177\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0831989921855\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0830446763289\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0828909373539\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0827377720319\n",
      "Truth:  -0.1415094 Pred:  -0.000794325 Error:  -0.140715075267 Loss:  0.0828457372148\n",
      "Truth:  0.3584906 Pred:  0.0994989 Error:  0.258991694759 Loss:  0.0831731460578\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0830203096546\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0828680393122\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0827163318915\n",
      "Truth:  0.0 Pred:  -0.0365125 Error:  0.0365125127137 Loss:  0.0826310849926\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.0827931007196\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0826423676755\n",
      "Truth:  -0.08490566 Pred:  -0.0463149 Error:  -0.0385907350446 Loss:  0.0825615389918\n",
      "Truth:  0.3207547 Pred:  -0.000794325 Error:  0.321549024733 Loss:  0.0829992450096\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0828489617916\n",
      "Truth:  0.0 Pred:  0.0199799 Error:  -0.0199798718095 Loss:  0.0827342371748\n",
      "Truth:  -0.009433962 Pred:  -0.03913 Error:  0.0296960737878 Loss:  0.0826376284983\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0824888224915\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0823405566153\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0821928279344\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0821479911655\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820011433921\n",
      "Truth:  -0.09433963 Pred:  -0.000794325 Error:  -0.0935453052671 Loss:  0.0820219436838\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081875850844\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817302825745\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081585236055\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814407084856\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081296697086\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811531990961\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810102117752\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808677324021\n",
      "Truth:  0.1886793 Pred:  -0.000794325 Error:  0.189473624733 Loss:  0.081060296041\n",
      "Truth:  0.2358491 Pred:  0.00230207 Error:  0.233547025428 Loss:  0.0813301840576\n",
      "Truth:  0.0 Pred:  -0.0231389 Error:  0.0231388546526 Loss:  0.0812273725215\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810855152944\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809441575645\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808032966984\n",
      "Truth:  -0.02830189 Pred:  -0.00607818 Error:  -0.022223709143 Loss:  0.0807005254922\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805605846852\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804211331818\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802821684201\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801436878562\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800056889638\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0799664396683\n",
      "Truth:  0.0 Pred:  -0.014768 Error:  0.0147680491209 Loss:  0.0798534441907\n",
      "Truth:  0.1320755 Pred:  0.00526379 Error:  0.126811714634 Loss:  0.0799346868732\n",
      "Truth:  -0.08490566 Pred:  -0.00172883 Error:  -0.0831768293738 Loss:  0.0799402864284\n",
      "Truth:  0.0 Pred:  -0.0157186 Error:  0.0157186277211 Loss:  0.0798295594307\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796935263245\n",
      "Truth:  0.0 Pred:  -0.0534812 Error:  0.0534811541438 Loss:  0.0796484878843\n",
      "Truth:  0.0 Pred:  -0.0073053 Error:  0.00730529846624 Loss:  0.0795244000808\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079389588308\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792552374301\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0791213450876\n",
      "Truth:  0.0 Pred:  -0.0105562 Error:  0.0105561967939 Loss:  0.0790045390428\n",
      "Truth:  0.0 Pred:  -0.00147585 Error:  0.00147585279774 Loss:  0.0788726875356\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078740126648\n",
      "Truth:  -0.5283019 Pred:  -0.00611632 Error:  -0.522185581018 Loss:  0.079491729113\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793585693763\n",
      "Truth:  0.2641509 Pred:  0.00370655 Error:  0.260444351404 Loss:  0.0796644575216\n",
      "Truth:  -0.01886792 Pred:  -0.0298562 Error:  0.0109883241021 Loss:  0.0795486461668\n",
      "Truth:  -0.0754717 Pred:  -0.0249984 Error:  -0.0504732847385 Loss:  0.0794996977469\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0794466968174\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793147297502\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0791832047837\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0790521197\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078921472296\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787912603834\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786614817883\n",
      "Truth:  0.2358491 Pred:  -0.000794325 Error:  0.236643424733 Loss:  0.078923910265\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787943421298\n",
      "Truth:  0.1037736 Pred:  4.89637e-06 Error:  0.10376870363 Loss:  0.0788356904104\n",
      "Truth:  0.0 Pred:  -0.0108618 Error:  0.0108618102968 Loss:  0.0787233368895\n",
      "Truth:  -0.7169811 Pred:  -0.0209577 Error:  -0.69602337674 Loss:  0.07974198382\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796119217786\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079482287573\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0793685700018\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792397597637\n",
      "Truth:  -0.06603774 Pred:  -0.0355205 Error:  -0.0305172162135 Loss:  0.0791600174665\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079031968949\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078904338208\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787771232024\n",
      "Truth:  0.0 Pred:  0.0557938 Error:  -0.0557937771082 Loss:  0.0787397519079\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786132171235\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784870925005\n",
      "Truth:  -0.5849057 Pred:  -0.000794325 Error:  -0.584111375267 Loss:  0.0793052547704\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0791784196653\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0790519937057\n",
      "Truth:  0.1603774 Pred:  -0.000744474 Error:  0.161121874295 Loss:  0.0791841513234\n",
      "Truth:  0.2924528 Pred:  -0.000794325 Error:  0.293247124733 Loss:  0.0795283040138\n",
      "Truth:  0.1037736 Pred:  0.0129988 Error:  0.0907748169704 Loss:  0.0795463562015\n",
      "Truth:  0.08490566 Pred:  -0.000794325 Error:  0.0856999847329 Loss:  0.0795562177857\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794301987568\n",
      "Truth:  -0.3584906 Pred:  -0.025102 Error:  -0.333388584415 Loss:  0.079835883079\n",
      "Truth:  -1.0 Pred:  -0.0390832 Error:  -0.960916828364 Loss:  0.0812411158466\n",
      "Truth:  -0.3962264 Pred:  -0.000794325 Error:  -0.395432075267 Loss:  0.0817414199221\n",
      "Truth:  0.05660377 Pred:  -0.000216182 Error:  0.0568199519139 Loss:  0.0817017991462\n",
      "Truth:  -0.3207547 Pred:  -0.062159 Error:  -0.258595675821 Loss:  0.0819825830775\n",
      "Truth:  0.3584906 Pred:  0.0284365 Error:  0.330054071481 Loss:  0.0823757233127\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0822466388212\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.0823862264767\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0822575326254\n",
      "Truth:  0.09433963 Pred:  -0.000794325 Error:  0.0951339547329 Loss:  0.0822778104555\n",
      "Truth:  0.0 Pred:  -0.0418281 Error:  0.0418280698359 Loss:  0.0822142102344\n",
      "Truth:  0.0 Pred:  6.92746e-05 Error:  -6.92745670676e-05 Loss:  0.0820852542914\n",
      "Truth:  -0.04716982 Pred:  -0.000794325 Error:  -0.0463754952671 Loss:  0.0820292828823\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0820940818523\n",
      "Truth:  0.7 Pred:  -0.000794325 Error:  0.700794324733 Loss:  0.0830608009818\n",
      "Truth:  -0.08490566 Pred:  -0.00881765 Error:  -0.0760880124162 Loss:  0.0830499229965\n",
      "Truth:  0.0 Pred:  0.0428314 Error:  -0.0428314059973 Loss:  0.0829872773314\n",
      "Truth:  0.0 Pred:  0.00721472 Error:  -0.00721471803263 Loss:  0.082869435093\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0827419892695\n",
      "Truth:  -0.05660377 Pred:  -0.000794325 Error:  -0.0558094452671 Loss:  0.0827002333873\n",
      "Truth:  -0.2169811 Pred:  -0.0421552 Error:  -0.174825893797 Loss:  0.0828428427687\n",
      "Truth:  0.0 Pred:  -0.000236095 Error:  0.000236094987486 Loss:  0.0827151661879\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0825887451363\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0824627136719\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0823370699966\n",
      "Truth:  -0.02830189 Pred:  -0.00133931 Error:  -0.0269625832944 Loss:  0.0822520093411\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.082127074242\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0820892044419\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819649003445\n",
      "Truth:  -0.08490566 Pred:  -0.010716 Error:  -0.074189670604 Loss:  0.0819530297647\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818293122265\n",
      "Truth:  0.3113208 Pred:  -0.000794325 Error:  0.312115124733 Loss:  0.0821798233567\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820561371886\n",
      "Truth:  -0.1037736 Pred:  -0.000794325 Error:  -0.102979275267 Loss:  0.0820878870187\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819647149547\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818419155746\n",
      "Truth:  0.0 Pred:  -0.00535793 Error:  0.00535792671144 Loss:  0.0817263808482\n",
      "Truth:  0.0 Pred:  0.00135816 Error:  -0.00135815679096 Loss:  0.0816051618074\n",
      "Truth:  0.0 Pred:  -0.0163509 Error:  0.0163509249687 Loss:  0.0815068873543\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0814114989452\n",
      "Truth:  -0.09433963 Pred:  -0.000811238 Error:  -0.0935283916925 Loss:  0.0814296924778\n",
      "Truth:  0.3773585 Pred:  -0.000794325 Error:  0.378152824733 Loss:  0.0818745547451\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817531771552\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816321624282\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815115089391\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813912150729\n",
      "Truth:  0.0 Pred:  -0.0317999 Error:  0.0317999459803 Loss:  0.0813174185415\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.081225806099\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811064715569\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0810433955616\n",
      "Truth:  0.0 Pred:  0.010636 Error:  -0.0106359943748 Loss:  0.0809392426013\n",
      "Truth:  0.01886792 Pred:  0.0206891 Error:  -0.00182120237883 Loss:  0.0808223769584\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807043414831\n",
      "Truth:  0.0 Pred:  -0.0121009 Error:  0.01210090518 Loss:  0.0806033054945\n",
      "Truth:  0.0 Pred:  -0.00294268 Error:  0.00294268131256 Loss:  0.0804890986942\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803720725944\n",
      "Truth:  -0.06603774 Pred:  -0.0424353 Error:  -0.0236024850984 Loss:  0.08028883273\n",
      "Truth:  -0.2924528 Pred:  -0.0145305 Error:  -0.277922260487 Loss:  0.080578193532\n",
      "Truth:  0.0 Pred:  -0.00140895 Error:  0.00140895368531 Loss:  0.0804624490293\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803461451982\n",
      "Truth:  0.0 Pred:  -0.0152204 Error:  0.015220394358 Loss:  0.0802512097014\n",
      "Truth:  0.0 Pred:  -0.0103764 Error:  0.0103763826191 Loss:  0.0801494996183\n",
      "Truth:  -0.03773585 Pred:  -0.0433468 Error:  0.00561094991007 Loss:  0.080041158703\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799261415275\n",
      "Truth:  -0.02830189 Pred:  -0.0102009 Error:  -0.0181010216393 Loss:  0.0798365399044\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797221517493\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796080941958\n",
      "Truth:  -0.1226415 Pred:  -0.0182379 Error:  -0.104403626088 Loss:  0.0796438741841\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795302581187\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794169690059\n",
      "Truth:  0.02830189 Pred:  0.00496285 Error:  0.0233390447602 Loss:  0.0793363972756\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792237113753\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0791113483572\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0790802850473\n",
      "Truth:  0.0 Pred:  -0.000911232 Error:  0.00091123173479 Loss:  0.0789686149711\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0788570967254\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787458961955\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786350120256\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0785489872858\n",
      "Truth:  -0.1320755 Pred:  -0.0228045 Error:  -0.109270997602 Loss:  0.0785925646054\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784823687983\n",
      "Truth:  -0.08490566 Pred:  -0.0263133 Error:  -0.0585924091156 Loss:  0.0784542358991\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0783445467591\n",
      "Truth:  -0.1037736 Pred:  -0.0632059 Error:  -0.0405676574884 Loss:  0.0782912648278\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0781821142079\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0780732706222\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0779647327768\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0778564993855\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0777485691689\n",
      "Truth:  -0.1132075 Pred:  -0.00162476 Error:  -0.111582738152 Loss:  0.0777958896849\n",
      "Truth:  -0.1981132 Pred:  -0.000794325 Error:  -0.197318875267 Loss:  0.077962821229\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0778551943162\n",
      "Truth:  -0.35 Pred:  -0.00246185 Error:  -0.347538154479 Loss:  0.0782307973248\n",
      "Truth:  0.1981132 Pred:  -0.000794325 Error:  0.198907524733 Loss:  0.0783986370013\n",
      "Truth:  -0.509434 Pred:  -0.0331281 Error:  -0.476305909797 Loss:  0.0789512859913\n",
      "Truth:  0.0 Pred:  -0.00114153 Error:  0.00114152836613 Loss:  0.0788433667713\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078735265605\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786274634738\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0786893534755\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0785819120566\n",
      "Truth:  -0.09433963 Pred:  -0.0142156 Error:  -0.0801240619195 Loss:  0.07858403623\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784770352513\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0783703282313\n",
      "Truth:  0.0 Pred:  -0.0129054 Error:  0.0129054281861 Loss:  0.0782805272711\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0781743817881\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0780685267169\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0779629608672\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0778576830553\n",
      "Truth:  -0.04716982 Pred:  -0.0081753 Error:  -0.0389945158405 Loss:  0.077804735961\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0778411484627\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0777364652783\n",
      "Truth:  -0.3490566 Pred:  -0.0168925 Error:  -0.332164062525 Loss:  0.0780816858987\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0779769604771\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0778725184801\n",
      "Truth:  0.0 Pred:  -0.0024709 Error:  0.00247090286575 Loss:  0.077770624405\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0778322508562\n",
      "Truth:  0.7547171 Pred:  0.0577566 Error:  0.696960463708 Loss:  0.0786666554557\n",
      "Truth:  0.2169811 Pred:  -0.000794325 Error:  0.217775424733 Loss:  0.0788538812555\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787489624968\n",
      "Truth:  0.0 Pred:  -0.0187738 Error:  0.0187737718225 Loss:  0.0786684588851\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0785640699654\n",
      "Truth:  0.0 Pred:  0.0505952 Error:  -0.0505952201784 Loss:  0.0785266283994\n",
      "Truth:  0.0 Pred:  -0.000895283 Error:  0.000895282893907 Loss:  0.0784228431781\n",
      "Truth:  0.02830189 Pred:  0.00197709 Error:  0.0263248046313 Loss:  0.0783532863843\n",
      "Truth:  -0.02830189 Pred:  -0.0627309 Error:  0.0344290481962 Loss:  0.0782947207334\n",
      "Truth:  0.0 Pred:  0.0774614 Error:  -0.0774613916874 Loss:  0.0782936111075\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0781905535458\n",
      "Truth:  -0.2830189 Pred:  -0.00443546 Error:  -0.278583435726 Loss:  0.0784566795514\n",
      "Truth:  0.0 Pred:  0.0177398 Error:  -0.0177397988737 Loss:  0.0783761531845\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0782733957958\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078170910252\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0780811577771\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0779791962559\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0778775034081\n",
      "Truth:  -0.1320755 Pred:  -0.00966174 Error:  -0.122413758445 Loss:  0.0779361037437\n",
      "Truth:  -0.0754717 Pred:  -0.0596641 Error:  -0.0158076368443 Loss:  0.0778544631827\n",
      "Truth:  -0.6603773 Pred:  -0.0181957 Error:  -0.64218164294 Loss:  0.0785950500328\n",
      "Truth:  -0.009433962 Pred:  -0.0378008 Error:  0.0283667933518 Loss:  0.0785292200764\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784274728312\n",
      "Truth:  0.02830189 Pred:  -0.000356702 Error:  0.0286585920467 Loss:  0.0783624154707\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0782611516447\n",
      "Truth:  -0.245283 Pred:  -0.0273816 Error:  -0.217901388012 Loss:  0.0784432119268\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0783421066049\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0782412642358\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0781406837949\n",
      "Truth:  -0.06603774 Pred:  -0.0195009 Error:  -0.0465368734677 Loss:  0.07809969312\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0779995566324\n",
      "Truth:  0.5566038 Pred:  0.00368228 Error:  0.552921519808 Loss:  0.0786139446831\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0785134025385\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784131198574\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0783130956369\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.0784075932291\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0783300431032\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0782305107304\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0783126558766\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078213400651\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0781143992752\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0781481841097\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0780495184728\n",
      "Truth:  -0.6132075 Pred:  -0.000794325 Error:  -0.612413175267 Loss:  0.0787302365069\n",
      "Truth:  0.0 Pred:  0.000130671 Error:  -0.000130670552608 Loss:  0.0786302370591\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0785313350104\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784326839822\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0783342830199\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.078391373579\n",
      "Truth:  0.4150943 Pred:  -0.000794325 Error:  0.415888624733 Loss:  0.0788180451987\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787195304001\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786212640625\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0785687706888\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078470941197\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078373357508\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0782760186964\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0781789238419\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0780820720282\n",
      "Truth:  0.0 Pred:  -0.0168987 Error:  0.0168987028301 Loss:  0.0780055928167\n",
      "Truth:  -0.06603774 Pred:  -0.000794325 Error:  -0.0652434152671 Loss:  0.0779896600108\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0778934064755\n",
      "Truth:  -0.2358491 Pred:  -0.000794325 Error:  -0.235054775267 Loss:  0.0780891242449\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0779929864345\n",
      "Truth:  0.0 Pred:  0.00235858 Error:  -0.00235857837833 Loss:  0.0778990306481\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0778033672413\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0777079409185\n",
      "Truth:  -0.4528302 Pred:  -0.00182279 Error:  -0.451007409171 Loss:  0.0781699452109\n",
      "Truth:  0.0 Pred:  -0.0287062 Error:  0.0287061873823 Loss:  0.0781088033594\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0781045670284\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0780092399726\n",
      "Truth:  0.4056604 Pred:  0.0317784 Error:  0.373882034626 Loss:  0.0783736153355\n",
      "Truth:  0.0 Pred:  -0.0587941 Error:  0.0587940551341 Loss:  0.0783495322356\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0782542555679\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078159212708\n",
      "Truth:  0.02830189 Pred:  -0.000794325 Error:  0.0290962147329 Loss:  0.0780990864849\n",
      "Truth:  0.009433962 Pred:  0.00385918 Error:  0.00557478453538 Loss:  0.0780103174495\n",
      "Truth:  0.5471698 Pred:  0.00700616 Error:  0.540163641879 Loss:  0.0785752970637\n",
      "Truth:  -0.2924528 Pred:  -0.0182622 Error:  -0.274190620432 Loss:  0.0788141436124\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787189974918\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786240831523\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0785293997479\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784349464368\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0783407223813\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0782467267478\n",
      "Truth:  0.0 Pred:  0.00600166 Error:  -0.00600165501237 Loss:  0.0781592629806\n",
      "Truth:  0.1603774 Pred:  -0.000794325 Error:  0.161171724733 Loss:  0.0782596408062\n",
      "Truth:  -0.08490566 Pred:  -0.0123922 Error:  -0.0725134631957 Loss:  0.0782527009781\n",
      "Truth:  0.0 Pred:  0.0727376 Error:  -0.0727376043797 Loss:  0.0782460482681\n",
      "Truth:  0.0 Pred:  -0.0421319 Error:  0.0421319305897 Loss:  0.078202537283\n",
      "Truth:  0.0 Pred:  -0.000979654 Error:  0.000979654025286 Loss:  0.0781096096256\n",
      "Truth:  -0.1698113 Pred:  -0.0249783 Error:  -0.14483298268 Loss:  0.0781898059875\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0780968942453\n",
      "Truth:  0.0 Pred:  -0.00352156 Error:  0.00352155929431 Loss:  0.0780074753784\n",
      "Truth:  0.3113208 Pred:  -0.000794325 Error:  0.312115124733 Loss:  0.0782878438208\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0781951482238\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0781026741216\n",
      "Truth:  -0.7830189 Pred:  -0.0597737 Error:  -0.723245227628 Loss:  0.0788725339707\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787794729346\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0786959731303\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786033433462\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0785109335854\n",
      "Truth:  0.0 Pred:  -0.0475311 Error:  0.0475311279297 Loss:  0.0784741841125\n",
      "Truth:  0.09433963 Pred:  -0.000794325 Error:  0.0951339547329 Loss:  0.0784939231772\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784019709897\n",
      "Truth:  0.0 Pred:  -0.0103136 Error:  0.010313604027 Loss:  0.0783214882864\n",
      "Truth:  0.509434 Pred:  0.0598364 Error:  0.44959760864 Loss:  0.0787598308134\n",
      "Truth:  0.1320755 Pred:  -0.000794325 Error:  0.132869824733 Loss:  0.0788236397685\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787317324481\n",
      "Truth:  0.3490566 Pred:  -0.000794325 Error:  0.349850924733 Loss:  0.0790506962037\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0789587380704\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0788669958012\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078775468637\n",
      "Truth:  0.0 Pred:  -0.00208529 Error:  0.00208528572693 Loss:  0.078685667486\n",
      "Truth:  0.1886793 Pred:  -0.0106279 Error:  0.199307234709 Loss:  0.0788267453424\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787355859726\n",
      "Truth:  -0.1698113 Pred:  -0.054038 Error:  -0.115773300638 Loss:  0.0787788038427\n",
      "Truth:  -0.03773585 Pred:  -0.00107522 Error:  -0.0366606342459 Loss:  0.0787297150669\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786389870223\n",
      "Truth:  0.0 Pred:  0.152754 Error:  -0.152754068375 Loss:  0.0787251673494\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786346553371\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0785443533294\n",
      "Truth:  -0.0754717 Pred:  -0.00348413 Error:  -0.0719875714913 Loss:  0.078536755668\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0784904517549\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784006296427\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0783110149719\n",
      "Truth:  -0.06603774 Pred:  -0.000794325 Error:  -0.0652434152671 Loss:  0.0782959427692\n",
      "Truth:  0.4150943 Pred:  -0.000592795 Error:  0.415687094851 Loss:  0.0786846422532\n",
      "Truth:  -0.5566038 Pred:  -0.0585783 Error:  -0.498025532306 Loss:  0.079167197938\n",
      "Truth:  0.09433963 Pred:  -0.000975314 Error:  0.0953149442367 Loss:  0.0791857585659\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0790957569197\n",
      "Truth:  -0.7169811 Pred:  -0.0211297 Error:  -0.695851402439 Loss:  0.079803045504\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797125429602\n",
      "Truth:  0.0 Pred:  -0.025438 Error:  0.0254380404949 Loss:  0.0796504439871\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079560322708\n",
      "Truth:  0.9339622 Pred:  0.0338268 Error:  0.900135379448 Loss:  0.0804970522248\n",
      "Truth:  0.0 Pred:  0.0750185 Error:  -0.0750185400248 Loss:  0.0804908053466\n",
      "Truth:  -0.1226415 Pred:  -0.0142864 Error:  -0.108355114151 Loss:  0.0805225414614\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804318381431\n",
      "Truth:  0.0 Pred:  -0.00269474 Error:  0.00269473623484 Loss:  0.0803435005273\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802532063437\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0801827079184\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800928003497\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800030961918\n",
      "Truth:  -0.009433962 Pred:  -0.0284917 Error:  0.0190577138537 Loss:  0.079934231353\n",
      "Truth:  -0.3962264 Pred:  -0.0117435 Error:  -0.38448285633 Loss:  0.0802779656927\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801883561764\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800989484833\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800097419324\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799207358457\n",
      "Truth:  0.0 Pred:  -0.0151585 Error:  0.0151585359126 Loss:  0.0798480509973\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797594257436\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796709989787\n",
      "Truth:  0.0 Pred:  -0.0599054 Error:  0.0599054135382 Loss:  0.0796488898228\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795607841634\n",
      "Truth:  0.02830189 Pred:  -0.000794325 Error:  0.0290962147329 Loss:  0.0795044620994\n",
      "Truth:  0.0 Pred:  -0.00209881 Error:  0.00209880550392 Loss:  0.0794181681678\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793306137765\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0794006617308\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793133213564\n",
      "Truth:  0.0 Pred:  0.0765041 Error:  -0.0765041410923 Loss:  0.0793102035092\n",
      "Truth:  -0.04716982 Pred:  -0.00120143 Error:  -0.0459683919927 Loss:  0.0792732391949\n",
      "Truth:  0.0 Pred:  -0.033802 Error:  0.0338020399213 Loss:  0.0792228834925\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0791361262372\n",
      "Truth:  0.02830189 Pred:  0.0208282 Error:  0.00747368763317 Loss:  0.0790569412222\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0789705586433\n",
      "Truth:  0.7452829 Pred:  -0.000794325 Error:  0.746077224733 Loss:  0.0797060676467\n",
      "Truth:  0.0 Pred:  0.00287075 Error:  -0.00287074549124 Loss:  0.0796214472479\n",
      "Truth:  0.0 Pred:  -0.0358723 Error:  0.0358722768724 Loss:  0.0795733183476\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794867480249\n",
      "Truth:  0.0 Pred:  -0.00483808 Error:  0.00483807828277 Loss:  0.0794048065652\n",
      "Truth:  0.03773585 Pred:  -0.0010127 Error:  0.0387485487472 Loss:  0.0793602273352\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0792827677623\n",
      "Truth:  -0.1698113 Pred:  -0.0282752 Error:  -0.141536087727 Loss:  0.0793508786156\n",
      "Truth:  0.2169811 Pred:  0.0332091 Error:  0.183771966107 Loss:  0.0794650000227\n",
      "Truth:  -0.08490566 Pred:  -0.0122572 Error:  -0.0726484975185 Loss:  0.0794575584261\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0794523455764\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793666614579\n",
      "Truth:  -0.2075472 Pred:  -0.0194128 Error:  -0.188134421682 Loss:  0.0794850159303\n",
      "Truth:  0.0 Pred:  -0.0342059 Error:  0.0342059209943 Loss:  0.0794357995228\n",
      "Truth:  0.0 Pred:  0.0112849 Error:  -0.0112849213183 Loss:  0.0793618029124\n",
      "Truth:  0.1037736 Pred:  0.00376737 Error:  0.100006231849 Loss:  0.0793841938331\n",
      "Truth:  -0.0754717 Pred:  -0.0169973 Error:  -0.0584744166754 Loss:  0.0793615396867\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.0794602886965\n",
      "Truth:  0.0 Pred:  -0.00137881 Error:  0.00137880840339 Loss:  0.0793758762854\n",
      "Truth:  0.0 Pred:  -0.0121951 Error:  0.0121951298788 Loss:  0.0793033268832\n",
      "Truth:  -0.5188679 Pred:  -0.0368745 Error:  -0.481993445532 Loss:  0.0797377283057\n",
      "Truth:  0.1509434 Pred:  -0.000503361 Error:  0.151446760759 Loss:  0.07981500097\n",
      "Truth:  0.8396227 Pred:  0.131982 Error:  0.707641178155 Loss:  0.0804908095568\n",
      "Truth:  0.0 Pred:  -0.0342737 Error:  0.0342736504972 Loss:  0.0804411136869\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803555639673\n",
      "Truth:  -0.2924528 Pred:  -0.000794325 Error:  -0.291658475267 Loss:  0.0805822838292\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804967661881\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0804501331679\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803649397899\n",
      "Truth:  0.0 Pred:  -0.0154602 Error:  0.0154601698741 Loss:  0.080295597087\n",
      "Truth:  -0.1792453 Pred:  -0.0557603 Error:  -0.123485043054 Loss:  0.0803416904124\n",
      "Truth:  -0.06603774 Pred:  -0.00380987 Error:  -0.0622278737374 Loss:  0.0803223793072\n",
      "Truth:  -0.1698113 Pred:  -0.000794325 Error:  -0.169016975267 Loss:  0.080416835746\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080332130947\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802476061795\n",
      "Truth:  0.0 Pred:  -0.0115387 Error:  0.0115387290716 Loss:  0.0801746668195\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800904883019\n",
      "Truth:  0.0 Pred:  0.00217276 Error:  -0.00217275531031 Loss:  0.0800079483305\n",
      "Truth:  0.0 Pred:  -0.000963132 Error:  0.000963131547906 Loss:  0.0799243030218\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798406561103\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0797654702403\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796821673442\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795990400074\n",
      "Truth:  0.02830189 Pred:  -0.000794325 Error:  0.0290962147329 Loss:  0.0795458791387\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794630699332\n",
      "Truth:  -0.1132075 Pred:  -0.0189061 Error:  -0.094301390965 Loss:  0.0794786564049\n",
      "Truth:  -0.01886792 Pred:  -0.0561908 Error:  0.0373228612953 Loss:  0.0794344215727\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.079429435151\n",
      "Truth:  0.0 Pred:  -0.00836168 Error:  0.00836167857051 Loss:  0.0793550186519\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792728421939\n",
      "Truth:  0.5377358 Pred:  -0.00446439 Error:  0.542200188825 Loss:  0.0797565698288\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796741457734\n",
      "Truth:  0.3301887 Pred:  -0.000794325 Error:  0.330983024733 Loss:  0.0799361988276\n",
      "Truth:  0.0 Pred:  -0.00388604 Error:  0.00388603517786 Loss:  0.0798569799071\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797747086738\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796926084826\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796106788006\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0795370573883\n",
      "Truth:  0.0 Pred:  0.0214997 Error:  -0.021499697119 Loss:  0.079476915046\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0795028891761\n",
      "Truth:  0.0 Pred:  -0.00381099 Error:  0.00381099269725 Loss:  0.0794246142056\n",
      "Truth:  -0.7547171 Pred:  -0.0361778 Error:  -0.718539349323 Loss:  0.0800848567006\n",
      "Truth:  0.0 Pred:  -0.00615146 Error:  0.00615146243945 Loss:  0.0800085580481\n",
      "Truth:  0.0 Pred:  -0.00451606 Error:  0.00451605813578 Loss:  0.0799307307286\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798492308254\n",
      "Truth:  0.0 Pred:  -0.0266167 Error:  0.0266167260706 Loss:  0.079794464874\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797132725409\n",
      "Truth:  0.0 Pred:  -0.0187533 Error:  0.0187533069402 Loss:  0.0796506853072\n",
      "Truth:  -0.1037736 Pred:  -0.000794325 Error:  -0.102979275267 Loss:  0.0796746120661\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795937920996\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795131375782\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794326479945\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793523228431\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792721616205\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.0792113971793\n",
      "Truth:  0.0 Pred:  -0.009195 Error:  0.00919500179589 Loss:  0.0791400973876\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0790603967033\n",
      "Truth:  0.0754717 Pred:  -0.000621259 Error:  0.0760929590961 Loss:  0.0790573810147\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0789779261352\n",
      "Truth:  0.0 Pred:  0.0363563 Error:  -0.036356292665 Loss:  0.0789346993265\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0788555297473\n",
      "Truth:  -0.09433963 Pred:  -0.0198401 Error:  -0.074499549709 Loss:  0.0788511208607\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0787721958898\n",
      "Truth:  0.02830189 Pred:  -0.000794325 Error:  0.0290962147329 Loss:  0.0787220181311\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078643382719\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.078564905846\n",
      "Truth:  0.0 Pred:  -0.00535598 Error:  0.00535598164424 Loss:  0.0784911808468\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784130149956\n",
      "Truth:  -0.3962264 Pred:  -0.00210816 Error:  -0.394118239128 Loss:  0.0787303066782\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0786520577003\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0785739656913\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0784960301793\n",
      "Truth:  0.3490566 Pred:  0.00430569 Error:  0.344750909939 Loss:  0.0787625515805\n",
      "Truth:  0.0 Pred:  0.00616619 Error:  -0.00616619316861 Loss:  0.0786899552221\n",
      "Truth:  0.0 Pred:  -0.0194419 Error:  0.0194419361651 Loss:  0.0786307663918\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0785530853123\n",
      "Truth:  -0.6886792 Pred:  -0.0426856 Error:  -0.645993553436 Loss:  0.0791188285508\n",
      "Truth:  -0.09433963 Pred:  -0.018022 Error:  -0.076317599408 Loss:  0.0791160384819\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0790381064284\n",
      "Truth:  -0.04716982 Pred:  -0.0031148 Error:  -0.0440550197983 Loss:  0.0790033319884\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0789256666386\n",
      "Truth:  0.1886793 Pred:  -0.000794325 Error:  0.189473624733 Loss:  0.079035337232\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0789577941076\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0788804045339\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0788031680554\n",
      "Truth:  0.5660377 Pred:  -0.000794325 Error:  0.566832024733 Loss:  0.0792854100086\n",
      "Truth:  0.0 Pred:  -0.0400809 Error:  0.0400809384882 Loss:  0.0792467086547\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0792902876647\n",
      "Truth:  0.0 Pred:  -0.0267965 Error:  0.0267965458333 Loss:  0.0792385696924\n",
      "Truth:  -0.04716982 Pred:  -0.0561392 Error:  0.00896936229938 Loss:  0.0791694070867\n",
      "Truth:  0.3018868 Pred:  0.0439768 Error:  0.257909975269 Loss:  0.0793451598578\n",
      "Truth:  0.0 Pred:  -0.00515251 Error:  0.00515250815079 Loss:  0.0792722790604\n",
      "Truth:  0.0 Pred:  -0.0346073 Error:  0.0346073172987 Loss:  0.0792284469095\n",
      "Truth:  0.2830189 Pred:  -0.000794325 Error:  0.283813224733 Loss:  0.0794290202211\n",
      "Truth:  -0.3396226 Pred:  -0.000880925 Error:  -0.338741675015 Loss:  0.0796829993149\n",
      "Truth:  -0.3113208 Pred:  -0.0216715 Error:  -0.28964925524 Loss:  0.0798884457493\n",
      "Truth:  -0.2641509 Pred:  -0.000794325 Error:  -0.263356575267 Loss:  0.0800677889844\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079990373492\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799131090542\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798359952293\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797590315774\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0797372796933\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0797064020111\n",
      "Truth:  0.1226415 Pred:  0.000721336 Error:  0.121920164181 Loss:  0.0797473862463\n",
      "Truth:  -0.2075472 Pred:  -0.00707232 Error:  -0.200474884449 Loss:  0.0798644837227\n",
      "Truth:  0.0 Pred:  0.00293434 Error:  -0.00293434271589 Loss:  0.0797899390124\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797134669754\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796371428533\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795609662174\n",
      "Truth:  -0.06603774 Pred:  -0.0103755 Error:  -0.0556622775276 Loss:  0.0795378979851\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794619639704\n",
      "Truth:  0.0 Pred:  -0.0344638 Error:  0.0344638116658 Loss:  0.0794186131493\n",
      "Truth:  -0.02830189 Pred:  -0.0110088 Error:  -0.0172930518084 Loss:  0.0793588195387\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0794012012745\n",
      "Truth:  0.4716981 Pred:  -0.000794325 Error:  0.472492424733 Loss:  0.0797788105189\n",
      "Truth:  -0.1698113 Pred:  -0.000794325 Error:  -0.169016975267 Loss:  0.0798644517519\n",
      "Truth:  0.0 Pred:  -0.0115673 Error:  0.0115672703832 Loss:  0.0797989702741\n",
      "Truth:  0.0 Pred:  -0.031996 Error:  0.0319960080087 Loss:  0.079753181996\n",
      "Truth:  -0.05660377 Pred:  -0.0252604 Error:  -0.0313433941874 Loss:  0.0797068568402\n",
      "Truth:  0.09433963 Pred:  -0.000794325 Error:  0.0951339547329 Loss:  0.0797216054998\n",
      "Truth:  -0.1603774 Pred:  -0.0424957 Error:  -0.117881739516 Loss:  0.0797580526192\n",
      "Truth:  0.3490566 Pred:  -0.000794325 Error:  0.349850924733 Loss:  0.0800157748254\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799402539006\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.0800086324443\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799332620278\n",
      "Truth:  0.0 Pred:  -0.00351885 Error:  0.0035188535694 Loss:  0.0798606247574\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797855380527\n",
      "Truth:  -0.1226415 Pred:  -0.0160936 Error:  -0.106547918085 Loss:  0.0798109293051\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.0798969906278\n",
      "Truth:  -0.04716982 Pred:  -0.0092751 Error:  -0.0378947179434 Loss:  0.0798572157484\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797824164191\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797077584875\n",
      "Truth:  0.0 Pred:  -0.00354929 Error:  0.00354928919114 Loss:  0.0796358430302\n",
      "Truth:  0.0 Pred:  -0.0321142 Error:  0.0321141667664 Loss:  0.0795910112601\n",
      "Truth:  0.0 Pred:  -0.029787 Error:  0.0297870412469 Loss:  0.0795440706663\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794699183632\n",
      "Truth:  0.0 Pred:  -0.0393222 Error:  0.039322219789 Loss:  0.0794321500673\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793582423367\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792844734\n",
      "Truth:  0.02830189 Pred:  -0.000255591 Error:  0.0285574808286 Loss:  0.079236887103\n",
      "Truth:  -0.02830189 Pred:  -0.0183462 Error:  -0.00995568464626 Loss:  0.0791719562666\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0790985689711\n",
      "Truth:  -0.1132075 Pred:  -0.0167536 Error:  -0.0964539326173 Loss:  0.0791148041102\n",
      "Truth:  -0.2641509 Pred:  -0.000794325 Error:  -0.263356575267 Loss:  0.0792869926814\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792137035423\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0791405511367\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0790675350822\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0789946549981\n",
      "Truth:  0.8396227 Pred:  -0.000794325 Error:  0.840417024733 Loss:  0.0797029548769\n",
      "Truth:  -0.2735849 Pred:  -0.0290179 Error:  -0.244567047381 Loss:  0.0798561742938\n",
      "Truth:  -0.06603774 Pred:  -0.0457491 Error:  -0.0202886419375 Loss:  0.0798008655358\n",
      "Truth:  -0.7358491 Pred:  -0.0234123 Error:  -0.712436836979 Loss:  0.0803877263627\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803139604669\n",
      "Truth:  -0.08490566 Pred:  -0.0131497 Error:  -0.0717559161003 Loss:  0.0803060363517\n",
      "Truth:  0.3 Pred:  0.072286 Error:  0.227714005113 Loss:  0.08044239895\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803687870515\n",
      "Truth:  -0.06603774 Pred:  -0.0428096 Error:  -0.0232281344016 Loss:  0.0803160255993\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802426660967\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801694418189\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800963523925\n",
      "Truth:  0.0 Pred:  -0.00138303 Error:  0.00138303032145 Loss:  0.0800239390328\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799511176961\n",
      "Truth:  -0.5660377 Pred:  -0.0611771 Error:  -0.50486061019 Loss:  0.0803413008848\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.0804068021911\n",
      "Truth:  0.0 Pred:  -0.0108529 Error:  0.0108528556302 Loss:  0.0803430497194\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802702029017\n",
      "Truth:  -0.8018868 Pred:  -0.0182459 Error:  -0.783640909263 Loss:  0.0809137259633\n",
      "Truth:  0.0 Pred:  -0.00864234 Error:  0.00864234473556 Loss:  0.0808476643717\n",
      "Truth:  0.0 Pred:  -0.00160368 Error:  0.00160368112847 Loss:  0.0807752954372\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080702320099\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080629477806\n",
      "Truth:  0.0 Pred:  0.00404135 Error:  -0.00404135044664 Loss:  0.0805597254132\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0805815709085\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805090370483\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0804437605726\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0804228479901\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803506553127\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0803213197053\n",
      "Truth:  -0.1698113 Pred:  -0.0350856 Error:  -0.134725688955 Loss:  0.0803705544286\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802986048538\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0802423943664\n",
      "Truth:  0.0 Pred:  0.00498235 Error:  -0.0049823471345 Loss:  0.080174470136\n",
      "Truth:  -0.245283 Pred:  -0.000794325 Error:  -0.244488675267 Loss:  0.0803226344328\n",
      "Truth:  -0.02830189 Pred:  -0.00611288 Error:  -0.0221890131861 Loss:  0.080270261801\n",
      "Truth:  -0.8207547 Pred:  -0.00597859 Error:  -0.814776114313 Loss:  0.0809313831804\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808593174804\n",
      "Truth:  0.0 Pred:  -0.0142651 Error:  0.0142650613561 Loss:  0.0807994843662\n",
      "Truth:  -0.1792453 Pred:  -0.000794325 Error:  -0.178450975267 Loss:  0.0808871427961\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808153106722\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807436072798\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806720322731\n",
      "Truth:  0.0 Pred:  -0.0059418 Error:  0.00594179844484 Loss:  0.0806051894879\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805338661056\n",
      "Truth:  -0.009433962 Pred:  -0.00409103 Error:  -0.00534293061628 Loss:  0.0804667313418\n",
      "Truth:  -0.5849057 Pred:  -0.000794325 Error:  -0.584111375267 Loss:  0.0809160129153\n",
      "Truth:  0.0 Pred:  -0.0179384 Error:  0.0179384220392 Loss:  0.0808598831552\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0808389910907\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807677769747\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806966894616\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806257282141\n",
      "Truth:  0.0 Pred:  0.0206129 Error:  -0.0206129215658 Loss:  0.0805724781638\n",
      "Truth:  -0.245283 Pred:  -0.000794325 Error:  -0.244488675267 Loss:  0.0807177939414\n",
      "Truth:  0.0 Pred:  0.0626084 Error:  -0.06260843575 Loss:  0.0807017537658\n",
      "Truth:  0.4150943 Pred:  0.0288538 Error:  0.386240481226 Loss:  0.0809721420202\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809012509351\n",
      "Truth:  0.0 Pred:  -0.000674057 Error:  0.000674056878779 Loss:  0.0808303788555\n",
      "Truth:  0.2264151 Pred:  0.0221939 Error:  0.20422120621 Loss:  0.0809392851462\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080868610578\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807980605464\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807276347226\n",
      "Truth:  -1.0 Pred:  -0.0199317 Error:  -0.980068275705 Loss:  0.0815186115396\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081447676314\n",
      "Truth:  0.08490566 Pred:  -0.000794325 Error:  0.0856999847329 Loss:  0.081451409684\n",
      "Truth:  0.2924528 Pred:  -0.000794325 Error:  0.293247124733 Loss:  0.0816371953989\n",
      "Truth:  0.1226415 Pred:  0.00216759 Error:  0.120473905614 Loss:  0.0816712328312\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0816664997243\n",
      "Truth:  0.09433963 Pred:  0.0113417 Error:  0.0829979091805 Loss:  0.0816676645619\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815969710831\n",
      "Truth:  0.009433962 Pred:  -0.0360655 Error:  0.0454994659549 Loss:  0.0815654448777\n",
      "Truth:  0.0 Pred:  -0.00684409 Error:  0.00684408703819 Loss:  0.0815002429948\n",
      "Truth:  -0.02830189 Pred:  -0.0237992 Error:  -0.00450269783963 Loss:  0.0814331134872\n",
      "Truth:  0.25 Pred:  -0.000794325 Error:  0.250794324733 Loss:  0.0815806406747\n",
      "Truth:  0.2641509 Pred:  -0.000794325 Error:  0.264945224733 Loss:  0.0817402269098\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816698391688\n",
      "Truth:  -0.3773585 Pred:  -0.0238675 Error:  -0.353490965526 Loss:  0.0819060000083\n",
      "Truth:  0.0 Pred:  -0.00634376 Error:  0.00634376099333 Loss:  0.081840407787\n",
      "Truth:  -0.0754717 Pred:  -0.00220934 Error:  -0.073262355354 Loss:  0.081832968019\n",
      "Truth:  0.5283019 Pred:  0.0123325 Error:  0.515969407492 Loss:  0.0822091694397\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0821386803967\n",
      "Truth:  0.0 Pred:  -0.0477957 Error:  0.0477957390249 Loss:  0.0821089719699\n",
      "Truth:  -0.1320755 Pred:  -0.0573418 Error:  -0.0747336785083 Loss:  0.0821025974725\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820323830746\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819622898405\n",
      "Truth:  0.0 Pred:  -0.0231727 Error:  0.0231727082282 Loss:  0.0819116091667\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818417407047\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817719924982\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081702364237\n",
      "Truth:  0.0 Pred:  -0.0327447 Error:  0.0327447429299 Loss:  0.0816603044248\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0816313806826\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815620521612\n",
      "Truth:  0.4528302 Pred:  0.0792638 Error:  0.37356643836 Loss:  0.0818122701443\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081742905465\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816736594592\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816045318227\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0815422219213\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814733243981\n",
      "Truth:  0.2735849 Pred:  -0.000794325 Error:  0.274379224733 Loss:  0.0816377795561\n",
      "Truth:  -0.08490566 Pred:  -0.0107986 Error:  -0.0741070455278 Loss:  0.0816313649615\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815625674805\n",
      "Truth:  0.1603774 Pred:  -0.000794325 Error:  0.161171724733 Loss:  0.0816302623421\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815615827009\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814930196636\n",
      "Truth:  0.0 Pred:  -0.0144649 Error:  0.0144649352878 Loss:  0.0814361680229\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813678274778\n",
      "Truth:  -0.1320755 Pred:  -0.0205315 Error:  -0.111543979753 Loss:  0.0813933788345\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813251901254\n",
      "Truth:  0.0 Pred:  -0.00315383 Error:  0.00315383425914 Loss:  0.0812591112109\n",
      "Truth:  -0.04716982 Pred:  -0.0156442 Error:  -0.0315256384803 Loss:  0.0812171065887\n",
      "Truth:  -0.02830189 Pred:  -0.0162589 Error:  -0.012043035581 Loss:  0.0811587318452\n",
      "Truth:  0.0 Pred:  -0.0416447 Error:  0.0416447408497 Loss:  0.0811254148208\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081057739092\n",
      "Truth:  0.09433963 Pred:  -0.000794325 Error:  0.0951339547329 Loss:  0.0810695877583\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810020728188\n",
      "Truth:  0.1792453 Pred:  -0.000794325 Error:  0.180039624733 Loss:  0.0810852976524\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810178828976\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809505812549\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808833924397\n",
      "Truth:  -0.3867925 Pred:  -0.0492389 Error:  -0.337553576063 Loss:  0.0810983590926\n",
      "Truth:  0.0 Pred:  -0.00385895 Error:  0.00385895208456 Loss:  0.0810337236056\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809666338072\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808996561054\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808327902194\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0807804472712\n",
      "Truth:  -0.6226415 Pred:  -0.0199468 Error:  -0.602694727395 Loss:  0.081215375838\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811484140968\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810815637729\n",
      "Truth:  0.4245283 Pred:  0.00374934 Error:  0.420778964582 Loss:  0.0813639390022\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812970207179\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812302135013\n",
      "Truth:  0.5188679 Pred:  0.166991 Error:  0.351877396331 Loss:  0.0814546307342\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813878036372\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813210871812\n",
      "Truth:  0.0 Pred:  -0.0100907 Error:  0.0100907366723 Loss:  0.0812621704314\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0812034647424\n",
      "Truth:  0.4056604 Pred:  -0.000794325 Error:  0.406454724733 Loss:  0.081472045469\n",
      "Truth:  -0.0754717 Pred:  -0.0425139 Error:  -0.0329578004949 Loss:  0.0814320172141\n",
      "Truth:  0.09433963 Pred:  -0.000794325 Error:  0.0951339547329 Loss:  0.081443313123\n",
      "Truth:  0.0 Pred:  -0.0264239 Error:  0.0264239348471 Loss:  0.0813979923831\n",
      "Truth:  -0.3018868 Pred:  -0.00280089 Error:  -0.299085905565 Loss:  0.0815771593898\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0816270989995\n",
      "Truth:  -1.0 Pred:  0.00242519 Error:  -1.00242519495 Loss:  0.0823837120611\n",
      "Truth:  0.0 Pred:  -0.00247689 Error:  0.00247689336538 Loss:  0.0823181071196\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0822512295295\n",
      "Truth:  0.2169811 Pred:  0.00119278 Error:  0.215788322117 Loss:  0.0823606861627\n",
      "Truth:  0.1792453 Pred:  -0.000794325 Error:  0.180039624733 Loss:  0.0824406852934\n",
      "Truth:  0.08490566 Pred:  0.00274087 Error:  0.0821647881403 Loss:  0.0824404595183\n",
      "Truth:  0.15 Pred:  -0.000794325 Error:  0.150794324733 Loss:  0.0824963498415\n",
      "Truth:  0.5566038 Pred:  -0.000794325 Error:  0.557398124733 Loss:  0.0828843414876\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0828173292291\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.082750426289\n",
      "Truth:  -0.2641509 Pred:  -0.00139047 Error:  -0.262760432136 Loss:  0.0828971337103\n",
      "Truth:  -0.2075472 Pred:  -0.00591538 Error:  -0.201631819451 Loss:  0.0829938231938\n",
      "Truth:  -0.06603774 Pred:  -0.0129783 Error:  -0.0530594879765 Loss:  0.0829694665337\n",
      "Truth:  0.2358491 Pred:  -0.000794325 Error:  0.236643424733 Loss:  0.0830944047111\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0830275484317\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0829608006852\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0828941612075\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0828276297355\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0827612060067\n",
      "Truth:  -0.03773585 Pred:  -0.0428489 Error:  0.00511308348813 Loss:  0.0826983839011\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0826321720505\n",
      "Truth:  0.009433962 Pred:  -0.0299151 Error:  0.0393490880406 Loss:  0.0825972099471\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0825311866338\n",
      "Truth:  -0.09433963 Pred:  -0.00124915 Error:  -0.0930904835851 Loss:  0.0825397021959\n",
      "Truth:  0.0 Pred:  0.0118053 Error:  -0.0118052521721 Loss:  0.0824827042506\n",
      "Truth:  0.04716982 Pred:  -0.000792091 Error:  0.0479619106064 Loss:  0.0824549097308\n",
      "Truth:  0.2264151 Pred:  -0.000794325 Error:  0.227209424733 Loss:  0.0825713654951\n",
      "Truth:  0.1886793 Pred:  -0.000794325 Error:  0.189473624733 Loss:  0.0826572997871\n",
      "Truth:  0.0 Pred:  -0.00302436 Error:  0.00302436086349 Loss:  0.0825933375871\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0825276882991\n",
      "Truth:  0.0 Pred:  -0.00227479 Error:  0.00227479217574 Loss:  0.082463331526\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0823978916167\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0823325564951\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0822673259097\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0822021996098\n",
      "Truth:  0.02830189 Pred:  -0.000794325 Error:  0.0290962147329 Loss:  0.0821597826889\n",
      "Truth:  -0.0754717 Pred:  -0.0308373 Error:  -0.0446344491266 Loss:  0.0821298342982\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820649734453\n",
      "Truth:  0.2830189 Pred:  -0.000794325 Error:  0.283813224733 Loss:  0.082225729024\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0821608951034\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820961643394\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.082031536486\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819670112979\n",
      "Truth:  -0.1132075 Pred:  -0.000794325 Error:  -0.112413175267 Loss:  0.0819911749201\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819267840794\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818624952843\n",
      "Truth:  0.0 Pred:  0.00272072 Error:  -0.00272071897052 Loss:  0.0817998335454\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817357469086\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816717615947\n",
      "Truth:  0.2641509 Pred:  0.0068676 Error:  0.257283298929 Loss:  0.0818104752892\n",
      "Truth:  0.1320755 Pred:  -0.000794325 Error:  0.132869824733 Loss:  0.0818507746969\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817868500518\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817230261548\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816593027678\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815956796537\n",
      "Truth:  0.0 Pred:  -0.00192554 Error:  0.00192553829402 Loss:  0.0815330458948\n",
      "Truth:  -0.1415094 Pred:  -0.000794325 Error:  -0.140715075267 Loss:  0.0815795360985\n",
      "Truth:  0.2735849 Pred:  -0.000794325 Error:  0.274379224733 Loss:  0.081730870234\n",
      "Truth:  -0.01886792 Pred:  -0.0564866 Error:  0.0376186605209 Loss:  0.0816962724225\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816328696422\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0816138917448\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081550652647\n",
      "Truth:  0.009433962 Pred:  0.00401269 Error:  0.00542126788332 Loss:  0.0814911300631\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081428085684\n",
      "Truth:  0.0 Pred:  -0.00114916 Error:  0.00114915985614 Loss:  0.0813654167333\n",
      "Truth:  -0.03773585 Pred:  -0.0203237 Error:  -0.0174121674236 Loss:  0.0813155312034\n",
      "Truth:  0.0 Pred:  -0.00337578 Error:  0.00337577587925 Loss:  0.0812547831478\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811921192394\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811295528623\n",
      "Truth:  -0.7830189 Pred:  -0.0157877 Error:  -0.767231168144 Loss:  0.0816630688929\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816002338158\n",
      "Truth:  0.0 Pred:  -0.0102683 Error:  0.0102683193982 Loss:  0.0815448518947\n",
      "Truth:  0.0 Pred:  -0.0389347 Error:  0.0389347486198 Loss:  0.0815117951815\n",
      "Truth:  0.0 Pred:  -0.0064162 Error:  0.00641620298848 Loss:  0.0814535815442\n",
      "Truth:  0.0 Pred:  -0.00330621 Error:  0.00330620747991 Loss:  0.0813930491088\n",
      "Truth:  0.0754717 Pred:  0.00506108 Error:  0.0704106174581 Loss:  0.0813845487747\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813222206819\n",
      "Truth:  -0.08490566 Pred:  -0.000794325 Error:  -0.0841113352671 Loss:  0.0813243761027\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812621907349\n",
      "Truth:  0.0 Pred:  -0.0123239 Error:  0.0123238675296 Loss:  0.0812089975843\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811469970655\n",
      "Truth:  -0.1320755 Pred:  -0.000794325 Error:  -0.131281175267 Loss:  0.0811856212397\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811237341755\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081061942322\n",
      "Truth:  0.2358491 Pred:  0.00315591 Error:  0.232693185166 Loss:  0.0811784920859\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811167530941\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810551088667\n",
      "Truth:  0.0 Pred:  -0.0102283 Error:  0.0102282613516 Loss:  0.0810007937996\n",
      "Truth:  0.0 Pred:  0.000929072 Error:  -0.000929072324652 Loss:  0.0809394361586\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808780693045\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808167963553\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0807988921492\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807377733047\n",
      "Truth:  -0.02830189 Pred:  -0.0132426 Error:  -0.0150592485361 Loss:  0.0806876370263\n",
      "Truth:  -0.02830189 Pred:  -0.0145591 Error:  -0.0137427886866 Loss:  0.0806365730687\n",
      "Truth:  0.0 Pred:  -0.0133999 Error:  0.0133999260142 Loss:  0.0805853256243\n",
      "Truth:  -0.1132075 Pred:  -0.00723103 Error:  -0.105976471715 Loss:  0.0806046638925\n",
      "Truth:  -0.1132075 Pred:  -0.000794325 Error:  -0.112413175267 Loss:  0.0806288712832\n",
      "Truth:  0.09433963 Pred:  -0.000794325 Error:  0.0951339547329 Loss:  0.0806399017649\n",
      "Truth:  0.0 Pred:  -0.0154307 Error:  0.0154307130724 Loss:  0.0805903507097\n",
      "Truth:  0.0 Pred:  -0.00718077 Error:  0.00718077225611 Loss:  0.0805346107108\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0804800621726\n",
      "Truth:  -0.02830189 Pred:  -0.0302413 Error:  0.00193943922292 Loss:  0.0804205165903\n",
      "Truth:  -0.25 Pred:  -0.000794325 Error:  -0.249205675267 Loss:  0.0805483841348\n",
      "Truth:  0.0 Pred:  -0.0297324 Error:  0.0297324210405 Loss:  0.0805099163353\n",
      "Truth:  -0.3018868 Pred:  -0.0247274 Error:  -0.277159444311 Loss:  0.0806586678694\n",
      "Truth:  0.1037736 Pred:  0.00325119 Error:  0.100522413661 Loss:  0.0806736820385\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806133501976\n",
      "Truth:  -0.02830189 Pred:  -0.000794325 Error:  -0.0275075652671 Loss:  0.08057327036\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0806055950616\n",
      "Truth:  0.0 Pred:  -0.00207265 Error:  0.00207264628261 Loss:  0.0805464142411\n",
      "Truth:  0.0 Pred:  -0.0167844 Error:  0.0167844127864 Loss:  0.0804984006858\n",
      "Truth:  -1.0 Pred:  -0.0448565 Error:  -0.955143529922 Loss:  0.0811565234317\n",
      "Truth:  -0.1415094 Pred:  -0.000794325 Error:  -0.140715075267 Loss:  0.0812013042977\n",
      "Truth:  0.03773585 Pred:  0.00310332 Error:  0.0346325334713 Loss:  0.0811663164909\n",
      "Truth:  0.0 Pred:  -0.0027842 Error:  0.00278419954702 Loss:  0.0811074710578\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810472211355\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080987061543\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809269920773\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808670125358\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080807122717\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0808248811639\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807651122644\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.0807195131096\n",
      "Truth:  -0.5 Pred:  -0.0515661 Error:  -0.448433943093 Loss:  0.0809937222296\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0809608964495\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809012042888\n",
      "Truth:  0.0 Pred:  -0.00137184 Error:  0.00137183954939 Loss:  0.0808420306544\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0808374472675\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0808060154156\n",
      "Truth:  -0.01886792 Pred:  -0.0191326 Error:  0.000264688547807 Loss:  0.0807462222999\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806869108032\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806276872405\n",
      "Truth:  0.5943396 Pred:  -0.000794325 Error:  0.595133924733 Loss:  0.081008802972\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809494288208\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808901425012\n",
      "Truth:  -0.3490566 Pred:  -0.0197081 Error:  -0.329348458315 Loss:  0.0810737776201\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810144870345\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809552839627\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808961682111\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808371395865\n",
      "Truth:  0.0 Pred:  -0.00226066 Error:  0.00226066098548 Loss:  0.080779277673\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807204219313\n",
      "Truth:  0.0 Pred:  -0.00770003 Error:  0.00770003395155 Loss:  0.0806667304695\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806080439113\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805494435301\n",
      "Truth:  -0.02830189 Pred:  -0.0119237 Error:  -0.0163782192313 Loss:  0.0805023626613\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804439256833\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803855743273\n",
      "Truth:  -0.5754717 Pred:  -0.000794325 Error:  -0.574677375267 Loss:  0.0807474277687\n",
      "Truth:  -0.01886792 Pred:  -0.0162838 Error:  -0.00258414338891 Loss:  0.0806902490676\n",
      "Truth:  0.0 Pred:  -0.0273339 Error:  0.0273338928819 Loss:  0.0806512458833\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805929135815\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805346664363\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804765042615\n",
      "Truth:  -0.03773585 Pred:  -0.0399832 Error:  0.00224733314552 Loss:  0.0804194859152\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803614923528\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080303583206\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802457582908\n",
      "Truth:  -0.09433963 Pred:  -0.0432547 Error:  -0.0510849378926 Loss:  0.0802245658341\n",
      "Truth:  1.0 Pred:  -0.000794325 Error:  1.00079432473 Loss:  0.0808930987019\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808349718702\n",
      "Truth:  -0.09433963 Pred:  -0.00898462 Error:  -0.0853550083858 Loss:  0.0808382496342\n",
      "Truth:  0.2358491 Pred:  -0.000794325 Error:  0.236643424733 Loss:  0.080951151935\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808931093375\n",
      "Truth:  -0.3018868 Pred:  -0.0160104 Error:  -0.285876422444 Loss:  0.0810414330083\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809834090688\n",
      "Truth:  -0.06603774 Pred:  -0.000794325 Error:  -0.0652434152671 Loss:  0.080972036241\n",
      "Truth:  0.0 Pred:  -0.0270766 Error:  0.0270766466856 Loss:  0.0809331226023\n",
      "Truth:  -0.3207547 Pred:  -0.0386556 Error:  -0.282099139536 Loss:  0.0810782640286\n",
      "Truth:  -0.1037736 Pred:  -0.0205928 Error:  -0.0831807651995 Loss:  0.0810797798911\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0810763117678\n",
      "Truth:  -0.1698113 Pred:  -0.00812956 Error:  -0.161681739611 Loss:  0.0811343430333\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081076544459\n",
      "Truth:  0.0 Pred:  -0.00806343 Error:  0.00806343369186 Loss:  0.0810240548035\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809664185032\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809088649542\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808513939784\n",
      "Truth:  0.4528302 Pred:  0.0146116 Error:  0.438218560918 Loss:  0.081107571159\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810500401802\n",
      "Truth:  -0.02830189 Pred:  -0.0397887 Error:  0.0114868329919 Loss:  0.0810002454721\n",
      "Truth:  0.0 Pred:  0.0245677 Error:  -0.0245677214116 Loss:  0.0809598788597\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809025768196\n",
      "Truth:  -0.2924528 Pred:  -0.0370472 Error:  -0.255405622447 Loss:  0.0810272218522\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809699535459\n",
      "Truth:  0.0 Pred:  -0.0100219 Error:  0.0100218728185 Loss:  0.0809193486381\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808622388563\n",
      "Truth:  -0.3301887 Pred:  -0.0557551 Error:  -0.274433565328 Loss:  0.0810001101715\n",
      "Truth:  -0.4905661 Pred:  -0.0453921 Error:  -0.445173992781 Loss:  0.0812593086644\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812020789461\n",
      "Truth:  0.0 Pred:  0.0168312 Error:  -0.0168312415481 Loss:  0.0811563285286\n",
      "Truth:  0.1509434 Pred:  0.0149279 Error:  0.13601546887 Loss:  0.0811952909863\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811382285546\n",
      "Truth:  -0.08490566 Pred:  -0.0316337 Error:  -0.0532719849016 Loss:  0.0811184652612\n",
      "Truth:  0.0 Pred:  -0.0239008 Error:  0.0239007733762 Loss:  0.0810779140976\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810210560314\n",
      "Truth:  0.0 Pred:  -0.055366 Error:  0.0553660467267 Loss:  0.08100289962\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809461750268\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808895306096\n",
      "Truth:  0.1981132 Pred:  -0.000794325 Error:  0.198907524733 Loss:  0.0809728766507\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809162933395\n",
      "Truth:  0.0 Pred:  -0.00252914 Error:  0.00252914289013 Loss:  0.0808610132616\n",
      "Truth:  0.5754717 Pred:  0.073639 Error:  0.50183272438 Loss:  0.0811576811341\n",
      "Truth:  0.0 Pred:  -0.00458063 Error:  0.00458062859252 Loss:  0.0811037536323\n",
      "Truth:  0.4716981 Pred:  0.105859 Error:  0.365839192896 Loss:  0.0813041304369\n",
      "Truth:  0.0 Pred:  -0.0114443 Error:  0.0114443022758 Loss:  0.081255002569\n",
      "Truth:  0.1603774 Pred:  -0.000794325 Error:  0.161171724733 Loss:  0.0813111633013\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.0812678705215\n",
      "Truth:  -0.04716982 Pred:  -0.000923757 Error:  -0.0462460627915 Loss:  0.0812432938143\n",
      "Truth:  0.0 Pred:  0.060755 Error:  -0.0607549883425 Loss:  0.0812289261386\n",
      "Truth:  -0.02830189 Pred:  -0.000794325 Error:  -0.0275075652671 Loss:  0.081191279775\n",
      "Truth:  0.0 Pred:  0.000608823 Error:  -0.000608822971117 Loss:  0.0811348494831\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810786279823\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810224851129\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0809730132761\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809170225718\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808611100123\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080805275434\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807495186739\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806938395695\n",
      "Truth:  -0.05660377 Pred:  -0.00289105 Error:  -0.0537127242378 Loss:  0.0806750635672\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0806719974762\n",
      "Truth:  0.5566038 Pred:  0.00572975 Error:  0.550874051598 Loss:  0.0809987535944\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.0810609805883\n",
      "Truth:  -0.2358491 Pred:  -0.000794325 Error:  -0.235054775267 Loss:  0.081167846511\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811121089786\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810564486984\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810008655101\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809453592535\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080889929769\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808345768975\n",
      "Truth:  -0.06603774 Pred:  -0.000794325 Error:  -0.0652434152671 Loss:  0.0808238095207\n",
      "Truth:  0.7358491 Pred:  0.0454147 Error:  0.690434417522 Loss:  0.0812445207754\n",
      "Truth:  0.1886793 Pred:  -0.000794325 Error:  0.189473624733 Loss:  0.0813191615367\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812636654397\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812082457836\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811529024105\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810976351631\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810424438845\n",
      "Truth:  0.0 Pred:  -0.0155919 Error:  0.0155918849632 Loss:  0.0809974915775\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809424447918\n",
      "Truth:  0.0754717 Pred:  0.0839827 Error:  -0.00851095391588 Loss:  0.0808927661286\n",
      "Truth:  -0.02830189 Pred:  -0.00732001 Error:  -0.020981882225 Loss:  0.0808517031513\n",
      "Truth:  0.1320755 Pred:  0.00314926 Error:  0.128926236672 Loss:  0.080884630914\n",
      "Truth:  0.0 Pred:  -0.0243139 Error:  0.0243139453232 Loss:  0.08084591039\n",
      "Truth:  -0.06603774 Pred:  -0.0257576 Error:  -0.0402801850815 Loss:  0.0808181636559\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0808139662612\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0808097746007\n",
      "Truth:  0.0 Pred:  0.00217845 Error:  -0.00217844522558 Loss:  0.0807561013383\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807015571524\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0806588659718\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806044623333\n",
      "Truth:  0.0 Pred:  -0.0263363 Error:  0.0263363141567 Loss:  0.080567520095\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805132526151\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0805296052134\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080475437224\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804213427824\n",
      "Truth:  -0.02830189 Pred:  -0.0417165 Error:  0.0134146409191 Loss:  0.0803758836902\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803219300909\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802680495995\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802142420674\n",
      "Truth:  -0.1320755 Pred:  -0.00817118 Error:  -0.123904316012 Loss:  0.0802438023339\n",
      "Truth:  0.4150943 Pred:  -0.000794325 Error:  0.415888624733 Loss:  0.0804707427142\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804169072966\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803631445805\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803094544187\n",
      "Truth:  0.0 Pred:  -0.0166379 Error:  0.0166378952563 Loss:  0.0802665201239\n",
      "Truth:  0.0 Pred:  -0.0206205 Error:  0.0206204801798 Loss:  0.0802263273746\n",
      "Truth:  0.0 Pred:  -0.00411808 Error:  0.00411807559431 Loss:  0.0801750760266\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801216569477\n",
      "Truth:  0.09433963 Pred:  0.0101576 Error:  0.0841820215729 Loss:  0.0801243875224\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800710743082\n",
      "Truth:  0.0 Pred:  -0.0173297 Error:  0.0173297096044 Loss:  0.0800289377301\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799757601375\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799226538763\n",
      "Truth:  0.0 Pred:  -0.0136543 Error:  0.0136542655528 Loss:  0.0798782380665\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0798305229956\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797776205871\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797247889511\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796720279456\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796193374291\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795667172604\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795141672988\n",
      "Truth:  0.6132075 Pred:  -0.000794325 Error:  0.614001824733 Loss:  0.0798704924037\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798178100802\n",
      "Truth:  0.0 Pred:  0.000999504 Error:  -0.000999504467472 Loss:  0.0797653345105\n",
      "Truth:  0.1981132 Pred:  -0.000794325 Error:  0.198907524733 Loss:  0.0798446040981\n",
      "Truth:  -0.1226415 Pred:  -0.00465561 Error:  -0.117985894818 Loss:  0.0798699639989\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798174220459\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797649498697\n",
      "Truth:  -0.7358491 Pred:  -0.0360899 Error:  -0.699759176767 Loss:  0.080176359443\n",
      "Truth:  0.0 Pred:  5.15319e-05 Error:  -5.15319406986e-05 Loss:  0.0801232262682\n",
      "Truth:  -0.01886792 Pred:  -0.00445652 Error:  -0.0144114027134 Loss:  0.0800796796655\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800271728079\n",
      "Truth:  0.009433962 Pred:  -0.0332954 Error:  0.0427293773419 Loss:  0.0800024886283\n",
      "Truth:  -0.03773585 Pred:  -0.000794325 Error:  -0.0369415252671 Loss:  0.0799740091551\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799216762507\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798694124782\n",
      "Truth:  1.0 Pred:  0.0258622 Error:  0.974137756974 Loss:  0.0804596886132\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804071389009\n",
      "Truth:  0.0 Pred:  -0.00143413 Error:  0.00143412756734 Loss:  0.080355080225\n",
      "Truth:  0.0 Pred:  0.0771894 Error:  -0.0771893560886 Loss:  0.0803529947677\n",
      "Truth:  0.5188679 Pred:  0.0503031 Error:  0.468564817087 Loss:  0.080608565421\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0805932953745\n",
      "Truth:  -0.3490566 Pred:  -0.0339785 Error:  -0.315078141506 Loss:  0.0807474602963\n",
      "Truth:  0.06603774 Pred:  0.0619894 Error:  0.00404835436534 Loss:  0.0806970666656\n",
      "Truth:  0.9811321 Pred:  0.029647 Error:  0.951485133394 Loss:  0.0812688250811\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812160202908\n",
      "Truth:  -0.2924528 Pred:  -0.000794325 Error:  -0.291658475267 Loss:  0.0813540153433\n",
      "Truth:  0.06603774 Pred:  -0.00427187 Error:  0.0703096053567 Loss:  0.0813467778531\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0813866972682\n",
      "Truth:  -0.2924528 Pred:  -0.0545548 Error:  -0.237897998566 Loss:  0.0814891261303\n",
      "Truth:  0.0 Pred:  -0.0123442 Error:  0.0123442076147 Loss:  0.0814439038161\n",
      "Truth:  -0.2075472 Pred:  -0.000794325 Error:  -0.206752875267 Loss:  0.0815258051046\n",
      "Truth:  -0.1415094 Pred:  -0.00168726 Error:  -0.139822141867 Loss:  0.0815638823984\n",
      "Truth:  0.0 Pred:  -0.0103507 Error:  0.0103506818414 Loss:  0.081517398586\n",
      "Truth:  0.0 Pred:  0.0165024 Error:  -0.0165023803711 Loss:  0.0814749882675\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814223933108\n",
      "Truth:  0.2641509 Pred:  0.00247436 Error:  0.261676544023 Loss:  0.081539822725\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.081579382557\n",
      "Truth:  0.4905661 Pred:  -0.000794325 Error:  0.491360424733 Loss:  0.0818459935148\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817932941203\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081740663211\n",
      "Truth:  -0.5000001 Pred:  -0.000794325 Error:  -0.499205775267 Loss:  0.0820117444526\n",
      "Truth:  0.0 Pred:  -0.00409593 Error:  0.00409592641518 Loss:  0.081961182598\n",
      "Truth:  0.01886792 Pred:  -0.0359628 Error:  0.0548307437784 Loss:  0.0819435882797\n",
      "Truth:  -0.1 Pred:  -0.00824416 Error:  -0.0917558366433 Loss:  0.0819499474815\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.081921825867\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818693161575\n",
      "Truth:  -0.5283019 Pred:  -0.000794325 Error:  -0.527507575267 Loss:  0.082157568589\n",
      "Truth:  0.0 Pred:  -0.0357241 Error:  0.0357241071761 Loss:  0.0821275534233\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820750125779\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820225395709\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081970134271\n",
      "Truth:  -0.009433962 Pred:  -0.0450745 Error:  0.0356405344182 Loss:  0.081940263478\n",
      "Truth:  0.2735849 Pred:  -0.000794325 Error:  0.274379224733 Loss:  0.0820642576541\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.082011926725\n",
      "Truth:  -0.1981132 Pred:  -0.000794325 Error:  -0.197318875267 Loss:  0.0820861268206\n",
      "Truth:  0.0 Pred:  -0.0198353 Error:  0.0198353491724 Loss:  0.0820460941661\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819938758053\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819417245201\n",
      "Truth:  0.0 Pred:  -0.00968115 Error:  0.00968115217984 Loss:  0.0818953441784\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818433229985\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817913685125\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081739480592\n",
      "Truth:  0.0 Pred:  0.00265544 Error:  -0.0026554397773 Loss:  0.0816888506043\n",
      "Truth:  0.0 Pred:  0.0102751 Error:  -0.0102750509977 Loss:  0.0816431603934\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815914667645\n",
      "Truth:  -0.4716981 Pred:  -0.0581896 Error:  -0.413508547723 Loss:  0.0818035543562\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817518243245\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817001603171\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816485622076\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815970298702\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081545563179\n",
      "Truth:  -0.1886793 Pred:  -0.0211246 Error:  -0.167554674421 Loss:  0.0816003111811\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815489078818\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814975699396\n",
      "Truth:  0.9500002 Pred:  0.0813856 Error:  0.868614632216 Loss:  0.081997644312\n",
      "Truth:  -0.05660377 Pred:  -0.0441741 Error:  -0.0124296985986 Loss:  0.0819534741878\n",
      "Truth:  0.08490566 Pred:  -0.00311512 Error:  0.0880207766186 Loss:  0.081957323999\n",
      "Truth:  0.2075472 Pred:  0.00453018 Error:  0.203017024411 Loss:  0.0820340898204\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0820722835054\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820208091807\n",
      "Truth:  0.6415094 Pred:  0.0512857 Error:  0.590223674913 Loss:  0.082342456564\n",
      "Truth:  -0.01886792 Pred:  -0.051707 Error:  0.0328391093427 Loss:  0.082311145149\n",
      "Truth:  0.1698113 Pred:  0.0414168 Error:  0.128394476136 Loss:  0.082340274941\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0822887613906\n",
      "Truth:  0.0 Pred:  -0.00123313 Error:  0.00123312987853 Loss:  0.0822375899061\n",
      "Truth:  0.0 Pred:  -0.0268873 Error:  0.026887293905 Loss:  0.0822026685837\n",
      "Truth:  0.0 Pred:  -0.0114011 Error:  0.0114010535181 Loss:  0.0821580269601\n",
      "Truth:  0.0 Pred:  -0.00041875 Error:  0.00041875030729 Loss:  0.0821065214297\n",
      "Truth:  -0.04716982 Pred:  -0.000794325 Error:  -0.0463754952671 Loss:  0.0820840207835\n",
      "Truth:  0.04716982 Pred:  0.00216775 Error:  0.0450020663576 Loss:  0.0820606841225\n",
      "Truth:  -0.06603774 Pred:  -0.00227402 Error:  -0.063763720822 Loss:  0.0820491765984\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.082033682518\n",
      "Truth:  0.0 Pred:  0.000187934 Error:  -0.000187934318092 Loss:  0.0819822718722\n",
      "Truth:  0.0 Pred:  -0.012603 Error:  0.0126029662788 Loss:  0.0819387192635\n",
      "Truth:  0.0 Pred:  -0.0665351 Error:  0.0665351375937 Loss:  0.0819290557869\n",
      "Truth:  -0.3679245 Pred:  -0.000794325 Error:  -0.367130175267 Loss:  0.0821078652662\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820569169326\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820060324039\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819552115606\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081904454283\n",
      "Truth:  -0.03773585 Pred:  -0.00152784 Error:  -0.0362080106597 Loss:  0.0818758940058\n",
      "Truth:  0.1320755 Pred:  0.0109691 Error:  0.121106377128 Loss:  0.0819003977429\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818497697323\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817992048882\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817487030926\n",
      "Truth:  0.1981132 Pred:  -0.000794325 Error:  0.198907524733 Loss:  0.0818216992432\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817712463325\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817208562133\n",
      "Truth:  0.5660377 Pred:  0.0507988 Error:  0.515238900157 Loss:  0.0819904569869\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819399932627\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818895922263\n",
      "Truth:  0.0 Pred:  -0.00111334 Error:  0.00111333781388 Loss:  0.0818394517829\n",
      "Truth:  -0.04716982 Pred:  -0.00300608 Error:  -0.0441637358764 Loss:  0.0818160797507\n",
      "Truth:  -0.1792453 Pred:  -0.000794325 Error:  -0.178450975267 Loss:  0.0818759897913\n",
      "Truth:  -0.3 Pred:  -0.0108239 Error:  -0.289176123403 Loss:  0.0820044285358\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819541436418\n",
      "Truth:  0.0 Pred:  -0.00418285 Error:  0.00418285094202 Loss:  0.0819060178418\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0819200326265\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818698931285\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818198155692\n",
      "Truth:  -0.2075472 Pred:  -0.00567692 Error:  -0.201870278077 Loss:  0.081893920793\n",
      "Truth:  -0.0754717 Pred:  -0.0196225 Error:  -0.0558491878383 Loss:  0.0818778537153\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818278638701\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817779356266\n",
      "Truth:  0.0 Pred:  -0.000484419 Error:  0.000484418618726 Loss:  0.0817278780422\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0817012948402\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081651536556\n",
      "Truth:  -0.1037736 Pred:  -0.00351999 Error:  -0.100253614641 Loss:  0.0816629699168\n",
      "Truth:  0.0 Pred:  -0.0155981 Error:  0.0155980717391 Loss:  0.0816223895126\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815727713021\n",
      "Truth:  -0.04716982 Pred:  -0.0434653 Error:  -0.00370455213315 Loss:  0.0815249993885\n",
      "Truth:  0.0 Pred:  0.0590938 Error:  -0.0590938292444 Loss:  0.0815112463719\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814617874738\n",
      "Truth:  -0.05660377 Pred:  -0.00266568 Error:  -0.0539380933578 Loss:  0.0814449327928\n",
      "Truth:  0.0 Pred:  -0.000915618 Error:  0.000915618496947 Loss:  0.0813956492467\n",
      "Truth:  0.6226415 Pred:  0.0131723 Error:  0.609469246034 Loss:  0.0817186300399\n",
      "Truth:  0.0 Pred:  -0.00644738 Error:  0.006447378546 Loss:  0.0816726207174\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816232143057\n",
      "Truth:  -0.09433963 Pred:  -0.0061152 Error:  -0.0882244267423 Loss:  0.0816272443499\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815779259121\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815286676187\n",
      "Truth:  -0.06603774 Pred:  -0.0172155 Error:  -0.0488222720106 Loss:  0.0815087368475\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0815045764567\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081455452749\n",
      "Truth:  0.0 Pred:  -0.0330744 Error:  0.0330743603408 Loss:  0.0814260238607\n",
      "Truth:  0.0 Pred:  0.0109662 Error:  -0.0109661575407 Loss:  0.0813831911152\n",
      "Truth:  0.1698113 Pred:  0.0650052 Error:  0.104806139132 Loss:  0.0813974213388\n",
      "Truth:  0.3962264 Pred:  0.0705677 Error:  0.325658687812 Loss:  0.0815457281187\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814967284807\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0815107195033\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814618004762\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814129407089\n",
      "Truth:  -0.06603774 Pred:  -0.0149555 Error:  -0.051082288288 Loss:  0.0813945807498\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813458207643\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812971197389\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812484775667\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811998941411\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0811570627546\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0811370429006\n",
      "Truth:  -0.1509434 Pred:  -0.00634672 Error:  -0.144596678798 Loss:  0.0811752946401\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811268723691\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081078508403\n",
      "Truth:  0.0 Pred:  -0.00213887 Error:  0.00213887472637 Loss:  0.0810310116318\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809827634737\n",
      "Truth:  0.0 Pred:  0.00528923 Error:  -0.00528923096135 Loss:  0.080937274572\n",
      "Truth:  0.4433962 Pred:  0.0696696 Error:  0.3737266106 Loss:  0.0811131240231\n",
      "Truth:  -0.254717 Pred:  -0.040586 Error:  -0.214131016455 Loss:  0.0811929666956\n",
      "Truth:  0.0 Pred:  0.00191755 Error:  -0.00191755359992 Loss:  0.0811454109589\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810972388448\n",
      "Truth:  0.0 Pred:  -0.00620072 Error:  0.00620072009042 Loss:  0.0810523637587\n",
      "Truth:  -0.009433962 Pred:  -0.00793453 Error:  -0.00149943080305 Loss:  0.0810047272719\n",
      "Truth:  -0.6509434 Pred:  -0.0458895 Error:  -0.605053854768 Loss:  0.0813183413518\n",
      "Truth:  0.2641509 Pred:  -0.000794325 Error:  0.264945224733 Loss:  0.0814281660428\n",
      "Truth:  0.02830189 Pred:  -8.25138e-05 Error:  0.0283844038413 Loss:  0.0813964602674\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813483108436\n",
      "Truth:  0.0 Pred:  -0.0622006 Error:  0.0622005648911 Loss:  0.0813368793535\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812888229366\n",
      "Truth:  0.0 Pred:  -0.0418409 Error:  0.0418408550322 Loss:  0.0812652999981\n",
      "Truth:  -0.03773585 Pred:  -0.0349315 Error:  -0.0028043877419 Loss:  0.0812185414091\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811706413397\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811227982941\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810750121706\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810272828677\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809796102841\n",
      "Truth:  0.0 Pred:  -0.0340381 Error:  0.0340381301939 Loss:  0.080951735296\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809041641324\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808566493997\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808091909974\n",
      "Truth:  -0.09433963 Pred:  -0.000794325 Error:  -0.0935453052671 Loss:  0.0808167360888\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0808419694154\n",
      "Truth:  0.0 Pred:  0.000857197 Error:  -0.00085719715571 Loss:  0.0807946411478\n",
      "Truth:  0.1226415 Pred:  -0.000794325 Error:  0.123435824733 Loss:  0.0808198576963\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807725612821\n",
      "Truth:  0.0 Pred:  -0.00955236 Error:  0.0095523558557 Loss:  0.0807304938246\n",
      "Truth:  0.245283 Pred:  0.000474935 Error:  0.244808064777 Loss:  0.0808273518948\n",
      "Truth:  -0.02830189 Pred:  -0.00173458 Error:  -0.0265673050808 Loss:  0.0807953400678\n",
      "Truth:  -0.5283019 Pred:  -0.0258005 Error:  -0.502501399935 Loss:  0.0810439875088\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809966983734\n",
      "Truth:  -0.3018868 Pred:  -0.0260459 Error:  -0.275840888986 Loss:  0.0811114476022\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810641744281\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810169568694\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809697948282\n",
      "Truth:  0.0 Pred:  -0.0233561 Error:  0.0233560651541 Loss:  0.0809359442232\n",
      "Truth:  0.05660377 Pred:  0.0570857 Error:  -0.000481889354925 Loss:  0.0808887016778\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808416979355\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807947493295\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807478557629\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080701017139\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806542333612\n",
      "Truth:  0.0 Pred:  -0.0141735 Error:  0.0141734741628 Loss:  0.0806153329755\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805686540233\n",
      "Truth:  -0.4056604 Pred:  -0.000794325 Error:  -0.404866075267 Loss:  0.0807581907979\n",
      "Truth:  0.0 Pred:  -0.0147671 Error:  0.0147671094164 Loss:  0.0807196446055\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806729865086\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.0807254559592\n",
      "Truth:  -0.1226415 Pred:  -0.000794325 Error:  -0.121847175267 Loss:  0.0807494336381\n",
      "Truth:  0.009433962 Pred:  0.00233856 Error:  0.00709539844229 Loss:  0.0807065117061\n",
      "Truth:  0.1509434 Pred:  0.000386423 Error:  0.15055697651 Loss:  0.0807471933979\n",
      "Truth:  -0.1698113 Pred:  -0.000794325 Error:  -0.169016975267 Loss:  0.080798572782\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0807849599385\n",
      "Truth:  -0.09433963 Pred:  -0.00417313 Error:  -0.0901664964777 Loss:  0.0807904143202\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807439319904\n",
      "Truth:  0.0 Pred:  -0.0253173 Error:  0.0253173075616 Loss:  0.0807117446359\n",
      "Truth:  0.0 Pred:  -0.0305527 Error:  0.0305526889861 Loss:  0.08068263317\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080636294244\n",
      "Truth:  -0.3018868 Pred:  -0.0152279 Error:  -0.286658900113 Loss:  0.0807557276387\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0807421948271\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806959019087\n",
      "Truth:  -0.4056604 Pred:  -0.00317736 Error:  -0.402483041231 Loss:  0.080882121318\n",
      "Truth:  0.4150943 Pred:  -0.000794325 Error:  0.415888624733 Loss:  0.0810758786942\n",
      "Truth:  0.0 Pred:  -0.0672805 Error:  0.0672804787755 Loss:  0.0810679044746\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810215303673\n",
      "Truth:  0.0 Pred:  -0.0171939 Error:  0.0171939283609 Loss:  0.0809846784031\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809384058389\n",
      "Truth:  0.0 Pred:  -0.0371284 Error:  0.0371283516288 Loss:  0.0809131405251\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808669625333\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808208377419\n",
      "Truth:  -0.1415094 Pred:  -0.00809369 Error:  -0.133415705775 Loss:  0.080851116883\n",
      "Truth:  -0.05660377 Pred:  -0.00426691 Error:  -0.052336861142 Loss:  0.0808347105218\n",
      "Truth:  0.0 Pred:  -0.00283183 Error:  0.00283183041029 Loss:  0.0807898555016\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807438810586\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806979594295\n",
      "Truth:  0.1415094 Pred:  -0.000794325 Error:  0.142303724733 Loss:  0.0807333243924\n",
      "Truth:  0.245283 Pred:  0.0117331 Error:  0.233549939297 Loss:  0.0808209988702\n",
      "Truth:  0.0 Pred:  -0.00226329 Error:  0.00226328941062 Loss:  0.080775954312\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807301195673\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806843373251\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806386074954\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805929299881\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805473047135\n",
      "Truth:  -0.2075472 Pred:  -0.0551158 Error:  -0.152431377297 Loss:  0.0805883813264\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805428107629\n",
      "Truth:  1.0 Pred:  0.0418249 Error:  0.95817508921 Loss:  0.0810437424287\n",
      "Truth:  -0.05660377 Pred:  -0.0450838 Error:  -0.011519960356 Loss:  0.0810040825416\n",
      "Truth:  -0.9150943 Pred:  -0.0509755 Error:  -0.864118783562 Loss:  0.0814505561454\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814045981788\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813586925561\n",
      "Truth:  0.0 Pred:  -0.000950196 Error:  0.000950196408667 Loss:  0.0813129279026\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812671266494\n",
      "Truth:  0.2264151 Pred:  -0.000794325 Error:  0.227209424733 Loss:  0.0813500955511\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813043252268\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812586068846\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0812343569231\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811887301323\n",
      "Truth:  -0.5283019 Pred:  -0.000794325 Error:  -0.527507575267 Loss:  0.0814417453507\n",
      "Truth:  0.0 Pred:  0.03664 Error:  -0.036639995873 Loss:  0.0814163619232\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0814027615454\n",
      "Truth:  0.1981132 Pred:  -0.000794325 Error:  0.198907524733 Loss:  0.0814692611284\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814236305083\n",
      "Truth:  0.3301887 Pred:  -0.000794325 Error:  0.330983024733 Loss:  0.081564704219\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815190712362\n",
      "Truth:  0.2264151 Pred:  -0.000794325 Error:  0.227209424733 Loss:  0.0816013356933\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815557335426\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0815421082528\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814965909002\n",
      "Truth:  -0.8867924 Pred:  -0.00370228 Error:  -0.88309011593 Loss:  0.0819481928862\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819024981406\n",
      "Truth:  0.0 Pred:  -0.0408509 Error:  0.0408509112895 Loss:  0.081879396516\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818337918637\n",
      "Truth:  1.0 Pred:  0.0041066 Error:  0.995893399697 Loss:  0.082347597152\n",
      "Truth:  0.0 Pred:  -0.00101652 Error:  0.00101652101148 Loss:  0.0823019055362\n",
      "Truth:  0.0 Pred:  0.000107825 Error:  -0.000107824860606 Loss:  0.0822557550136\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0822100415286\n",
      "Truth:  -0.2358491 Pred:  -0.000794325 Error:  -0.235054775267 Loss:  0.082295764879\n",
      "Truth:  0.0 Pred:  -0.010565 Error:  0.0105650108308 Loss:  0.0822555570572\n",
      "Truth:  0.0 Pred:  -0.0222146 Error:  0.0222145672888 Loss:  0.0822219206484\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0821763284894\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0821307873569\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820852971653\n",
      "Truth:  0.0 Pred:  -0.00137086 Error:  0.00137085805181 Loss:  0.0820401800948\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819947913488\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819494532882\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081904165828\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.0818904981922\n",
      "Truth:  0.2264151 Pred:  -0.000794325 Error:  0.227209424733 Loss:  0.0819715009383\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819262768847\n",
      "Truth:  0.254717 Pred:  -0.000794325 Error:  0.255511324733 Loss:  0.0820229278022\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819777254633\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081932573405\n",
      "Truth:  0.0 Pred:  -0.0237675 Error:  0.0237674806267 Loss:  0.0819002415024\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818551826598\n",
      "Truth:  -0.1886793 Pred:  -0.0525322 Error:  -0.136147055526 Loss:  0.0818853280639\n",
      "Truth:  -0.4245283 Pred:  -0.0164646 Error:  -0.408063658682 Loss:  0.0820663371264\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0820308447571\n",
      "Truth:  0.0 Pred:  0.0441981 Error:  -0.0441981181502 Loss:  0.0820098731792\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0819701049872\n",
      "Truth:  0.0 Pred:  -0.0126395 Error:  0.0126394713297 Loss:  0.0819317159321\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.081897255793\n",
      "Truth:  0.3490566 Pred:  -0.000745205 Error:  0.349801805325 Loss:  0.0820454330881\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820005181581\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819556528579\n",
      "Truth:  0.3 Pred:  -0.000794325 Error:  0.300794324733 Loss:  0.0820764914398\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0820316337319\n",
      "Truth:  0.0 Pred:  -0.0235622 Error:  0.0235622171313 Loss:  0.0819993836401\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819546178964\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819099014815\n",
      "Truth:  0.1132075 Pred:  -0.0104732 Error:  0.12368068615 Loss:  0.0819329030149\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818882477709\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0818842813944\n",
      "Truth:  0.245283 Pred:  0.00822419 Error:  0.237058812581 Loss:  0.0819695889981\n",
      "Truth:  0.0 Pred:  0.00763093 Error:  -0.00763093167916 Loss:  0.081928743582\n",
      "Truth:  -0.2075472 Pred:  -0.0170799 Error:  -0.190467269247 Loss:  0.0819883473853\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0819437842554\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818992700154\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818548045848\n",
      "Truth:  -0.06603774 Pred:  -0.0274398 Error:  -0.0385978961368 Loss:  0.0818311021692\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817867227731\n",
      "Truth:  -0.02830189 Pred:  -0.000794325 Error:  -0.0275075652671 Loss:  0.0817570133272\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817127230162\n",
      "Truth:  0.0 Pred:  -0.0376804 Error:  0.0376803986728 Loss:  0.0816886484813\n",
      "Truth:  0.3773585 Pred:  0.00704131 Error:  0.37031718678 Loss:  0.081846368994\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0818021024488\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817578842295\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817137142571\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816695924526\n",
      "Truth:  0.0 Pred:  -0.0191246 Error:  0.0191246494651 Loss:  0.081635508015\n",
      "Truth:  0.1792453 Pred:  -0.000794325 Error:  0.180039624733 Loss:  0.0816891050284\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816450686755\n",
      "Truth:  0.09433963 Pred:  -0.000794325 Error:  0.0951339547329 Loss:  0.0816524075689\n",
      "Truth:  -0.0754717 Pred:  -0.0221063 Error:  -0.0533654250376 Loss:  0.0816370258492\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815930895986\n",
      "Truth:  0.0 Pred:  -0.0334236 Error:  0.0334235616028 Loss:  0.0815669247273\n",
      "Truth:  -0.09433963 Pred:  -0.0028325 Error:  -0.0915071320643 Loss:  0.0815723211483\n",
      "Truth:  0.0 Pred:  0.0207299 Error:  -0.0207298509777 Loss:  0.0815393084135\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814955204614\n",
      "Truth:  0.1792453 Pred:  -0.000794325 Error:  0.180039624733 Loss:  0.0815489319\n",
      "Truth:  0.5660377 Pred:  -0.000794325 Error:  0.566832024733 Loss:  0.0818118154823\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817679511126\n",
      "Truth:  0.0 Pred:  -0.00192821 Error:  0.00192820932716 Loss:  0.0817247477891\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816809779551\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.0817290453318\n",
      "Truth:  0.0 Pred:  -0.017908 Error:  0.0179079696536 Loss:  0.0816945660905\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.0817425742215\n",
      "Truth:  -0.1226415 Pred:  -0.0250438 Error:  -0.0975976697245 Loss:  0.0817511306681\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0817074646454\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816638457021\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0816202737619\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081576748749\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815332705875\n",
      "Truth:  0.254717 Pred:  -0.000794325 Error:  0.255511324733 Loss:  0.0816268574913\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815833991403\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815399874937\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814966224761\n",
      "Truth:  0.0 Pred:  -0.0124014 Error:  0.0124013721943 Loss:  0.0814595343117\n",
      "Truth:  0.3207547 Pred:  0.0793478 Error:  0.24140688091 Loss:  0.081545342974\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815020448409\n",
      "Truth:  -0.1886793 Pred:  -0.023383 Error:  -0.165296349426 Loss:  0.0815469506848\n",
      "Truth:  0.1037736 Pred:  -0.000794325 Error:  0.104567924733 Loss:  0.0815592811476\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815160450895\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0814930456939\n",
      "Truth:  0.0 Pred:  -0.0347968 Error:  0.0347968377173 Loss:  0.0814680744597\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814249564748\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813818845562\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813388586299\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812958786225\n",
      "Truth:  -0.01886792 Pred:  -0.0509712 Error:  0.032103278827 Loss:  0.0812696425693\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812267452783\n",
      "Truth:  0.0 Pred:  0.0337328 Error:  -0.0337328054011 Loss:  0.0812014421671\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811586268756\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.0811961889287\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811534219797\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811107005032\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810680244268\n",
      "Truth:  -0.4245283 Pred:  -0.00216391 Error:  -0.422364385502 Loss:  0.0812492758135\n",
      "Truth:  0.0 Pred:  -0.00928 Error:  0.00927999895066 Loss:  0.0812110755603\n",
      "Truth:  0.1981132 Pred:  0.0337835 Error:  0.164329667321 Loss:  0.081255170304\n",
      "Truth:  0.06603774 Pred:  -0.000794325 Error:  0.0668320647329 Loss:  0.0812475228461\n",
      "Truth:  0.2641509 Pred:  0.00246091 Error:  0.261689985103 Loss:  0.0813431468325\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813004832614\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812578648609\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812152915593\n",
      "Truth:  0.06603774 Pred:  -0.000794325 Error:  0.0668320647329 Loss:  0.0812076854108\n",
      "Truth:  -0.09433963 Pred:  -0.000794325 Error:  -0.0935453052671 Loss:  0.0812142063515\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811717235826\n",
      "Truth:  0.1320755 Pred:  0.137479 Error:  -0.00540341783714 Loss:  0.0811317191973\n",
      "Truth:  0.0 Pred:  -0.00336696 Error:  0.00336696417071 Loss:  0.0810906823872\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810483319876\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810060262379\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0809728690034\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809306475478\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808884705358\n",
      "Truth:  0.02830189 Pred:  0.00143725 Error:  0.0268646415707 Loss:  0.0808600518988\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808179563535\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807759050494\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807338979169\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806919348863\n",
      "Truth:  0.0 Pred:  -0.000846044 Error:  0.000846044335049 Loss:  0.0806500430235\n",
      "Truth:  0.1698113 Pred:  0.00583376 Error:  0.16397753963 Loss:  0.0806937386169\n",
      "Truth:  -0.6226415 Pred:  -0.00661919 Error:  -0.616022309668 Loss:  0.0809743091468\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.0809421917742\n",
      "Truth:  -0.4056604 Pred:  -0.0478965 Error:  -0.35776391795 Loss:  0.0810871246151\n",
      "Truth:  -0.7169811 Pred:  -0.0301501 Error:  -0.686831021763 Loss:  0.08140410206\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813619421346\n",
      "Truth:  -0.1886793 Pred:  -0.0427041 Error:  -0.145975239326 Loss:  0.0813957180348\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813536065441\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081311539034\n",
      "Truth:  0.0 Pred:  -0.00670761 Error:  0.00670760544017 Loss:  0.0812726016991\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081230620334\n",
      "Truth:  -0.04716982 Pred:  -0.00592954 Error:  -0.0412402777602 Loss:  0.0812097703118\n",
      "Truth:  0.0 Pred:  -0.0265576 Error:  0.0265576075763 Loss:  0.0811812908106\n",
      "Truth:  -0.1320755 Pred:  -0.0140641 Error:  -0.11801135752 Loss:  0.081200473137\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081158616735\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811168038879\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.081075034528\n",
      "Truth:  0.0 Pred:  -0.0036158 Error:  0.00361579889432 Loss:  0.08103477505\n",
      "Truth:  0.1132075 Pred:  -0.000794325 Error:  0.114001824733 Loss:  0.0810519007901\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810102301899\n",
      "Truth:  -0.2641509 Pred:  -0.000794325 Error:  -0.263356575267 Loss:  0.0811048572501\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810632024096\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810215907571\n",
      "Truth:  0.1698113 Pred:  -0.000794325 Error:  0.170605624733 Loss:  0.081068007355\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810264363127\n",
      "Truth:  0.0 Pred:  0.150842 Error:  -0.1508423388 Loss:  0.0810625729082\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810210476893\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809795654127\n",
      "Truth:  0.35 Pred:  -0.000794325 Error:  0.350794324733 Loss:  0.0811190045648\n",
      "Truth:  0.02830189 Pred:  -0.000794325 Error:  0.0290962147329 Loss:  0.0810921332891\n",
      "Truth:  0.0 Pred:  -0.00617237 Error:  0.00617236597463 Loss:  0.0810534550406\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810120416606\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809706709969\n",
      "Truth:  -0.02830189 Pred:  -0.000794325 Error:  -0.0275075652671 Loss:  0.080943112695\n",
      "Truth:  -0.05660377 Pred:  -0.0157044 Error:  -0.0408993672999 Loss:  0.0809224822234\n",
      "Truth:  0.0 Pred:  -0.00296561 Error:  0.00296560954303 Loss:  0.0808823396525\n",
      "Truth:  0.0 Pred:  -0.0240505 Error:  0.0240504592657 Loss:  0.0808530901001\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808119076076\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807707674622\n",
      "Truth:  0.0 Pred:  -0.00740201 Error:  0.00740201352164 Loss:  0.080733065122\n",
      "Truth:  0.03773585 Pred:  0.0382102 Error:  -0.000474374360228 Loss:  0.080691843401\n",
      "Truth:  0.0 Pred:  -0.00699056 Error:  0.0069905621931 Loss:  0.0806540090677\n",
      "Truth:  -0.2075472 Pred:  -0.0550153 Error:  -0.152531855827 Loss:  0.0806908884145\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806499158177\n",
      "Truth:  -0.5849057 Pred:  -0.000794325 Error:  -0.584111375267 Loss:  0.0809079688466\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808669270208\n",
      "Truth:  -0.4245283 Pred:  -0.0256188 Error:  -0.39890951587 Loss:  0.0810297752485\n",
      "Truth:  0.009433962 Pred:  -0.000794325 Error:  0.0102282867329 Loss:  0.0809935411193\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0809613570038\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809203718135\n",
      "Truth:  0.0 Pred:  0.00545695 Error:  -0.00545695377514 Loss:  0.080881811048\n",
      "Truth:  -0.7358491 Pred:  -0.0331329 Error:  -0.702716233975 Loss:  0.0811993975765\n",
      "Truth:  0.3018868 Pred:  0.017549 Error:  0.284337821671 Loss:  0.0813030925352\n",
      "Truth:  -0.09433963 Pred:  -0.0461934 Error:  -0.0481462202889 Loss:  0.0812861757637\n",
      "Truth:  0.4339623 Pred:  -0.000794325 Error:  0.434756624733 Loss:  0.0814664258652\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0814253085863\n",
      "Truth:  0.0 Pred:  -0.0487259 Error:  0.0487259142101 Loss:  0.0814086507186\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813676047277\n",
      "Truth:  0.0 Pred:  0.0951229 Error:  -0.0951229184866 Loss:  0.0813746048874\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813336179697\n",
      "Truth:  0.0 Pred:  -0.0298563 Error:  0.0298562720418 Loss:  0.0813074474837\n",
      "Truth:  0.0 Pred:  -0.00592211 Error:  0.00592211214826 Loss:  0.0812691419272\n",
      "Truth:  -0.8018868 Pred:  -0.000794325 Error:  -0.801092475267 Loss:  0.0816347200548\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815936843211\n",
      "Truth:  0.0 Pred:  -0.0541436 Error:  0.0541435591877 Loss:  0.081579757317\n",
      "Truth:  0.0 Pred:  -0.0509652 Error:  0.0509652160108 Loss:  0.0815642327018\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.08152329509\n",
      "Truth:  0.009433962 Pred:  -0.0314028 Error:  0.0408367287046 Loss:  0.0815026838608\n",
      "Truth:  0.0 Pred:  -0.0530145 Error:  0.0530144795775 Loss:  0.0814882594536\n",
      "Truth:  0.245283 Pred:  0.0112201 Error:  0.234062885694 Loss:  0.0815654733333\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0815246179217\n",
      "Truth:  0.01886792 Pred:  -0.000748181 Error:  0.0196161007261 Loss:  0.0814933193792\n",
      "Truth:  0.009433962 Pred:  0.00134775 Error:  0.00808621320448 Loss:  0.0814562263493\n",
      "Truth:  0.0 Pred:  -0.00530611 Error:  0.00530610699207 Loss:  0.081417766693\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813770683377\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.0814125681643\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813719134778\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0813312997738\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812907269904\n",
      "Truth:  -0.02830189 Pred:  -0.0241732 Error:  -0.0041286675178 Loss:  0.0812518739896\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812113820172\n",
      "Truth:  0.3301887 Pred:  -0.000794325 Error:  0.330983024733 Loss:  0.0813370216765\n",
      "Truth:  0.01886792 Pred:  -0.000352906 Error:  0.0192208258304 Loss:  0.0813057918143\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812653337907\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812249164079\n",
      "Truth:  0.1509434 Pred:  0.00138298 Error:  0.149560417409 Loss:  0.0812592213783\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0812188476218\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811785143606\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811382215337\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810979690804\n",
      "Truth:  -0.02830189 Pred:  -0.000794325 Error:  -0.0275075652671 Loss:  0.0810711336253\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0810545635608\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810144133663\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080974303322\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809342333677\n",
      "Truth:  -0.009433962 Pred:  -0.000794325 Error:  -0.00863963726715 Loss:  0.0808981221808\n",
      "Truth:  0.0 Pred:  -0.0184512 Error:  0.0184512212873 Loss:  0.0808669454954\n",
      "Truth:  0.05660377 Pred:  -0.000794325 Error:  0.0573980947329 Loss:  0.080855234492\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808153038637\n",
      "Truth:  -0.2641509 Pred:  -0.000794325 Error:  -0.263356575267 Loss:  0.0809063015065\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808663852251\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808265087009\n",
      "Truth:  -0.08490566 Pred:  -0.00387649 Error:  -0.0810291669204 Loss:  0.0808266095761\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080786792519\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807470150611\n",
      "Truth:  0.1509434 Pred:  0.00200549 Error:  0.148937908361 Loss:  0.0807809071552\n",
      "Truth:  -0.1037736 Pred:  -0.00172269 Error:  -0.102050914357 Loss:  0.0807914734777\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080751752947\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807120718412\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806724301016\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806328276696\n",
      "Truth:  0.5500001 Pred:  -0.000794325 Error:  0.550794424733 Loss:  0.0808658116126\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808261526295\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807865329127\n",
      "Truth:  0.0 Pred:  0.000265936 Error:  -0.000265936309006 Loss:  0.080746690955\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807071497254\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806676475875\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806281844833\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080588760355\n",
      "Truth:  0.0 Pred:  -0.00213003 Error:  0.00213002576493 Loss:  0.0805500344248\n",
      "Truth:  -0.1037736 Pred:  -0.021712 Error:  -0.0820616432904 Loss:  0.0805507801618\n",
      "Truth:  -0.1886793 Pred:  -0.031092 Error:  -0.157587257897 Loss:  0.0805887665907\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805494396109\n",
      "Truth:  0.1132075 Pred:  -0.000794325 Error:  0.114001824733 Loss:  0.0805659186184\n",
      "Truth:  0.5283019 Pred:  -0.000794325 Error:  0.529096224733 Loss:  0.0807867607189\n",
      "Truth:  0.0 Pred:  -0.0158587 Error:  0.0158586744219 Loss:  0.0807548079205\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080715476645\n",
      "Truth:  0.4056604 Pred:  0.00274512 Error:  0.402915277351 Loss:  0.0808738836266\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080834532492\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807952200128\n",
      "Truth:  -0.1981132 Pred:  -0.0531364 Error:  -0.144976780495 Loss:  0.0808267278972\n",
      "Truth:  0.0 Pred:  0.0163123 Error:  -0.0163122508675 Loss:  0.0807950721185\n",
      "Truth:  -0.3584906 Pred:  -0.000794325 Error:  -0.357696275267 Loss:  0.0809308745722\n",
      "Truth:  0.0 Pred:  -0.0031437 Error:  0.00314370100386 Loss:  0.0808927436047\n",
      "Truth:  -0.15 Pred:  -0.000794325 Error:  -0.149205675267 Loss:  0.0809262139289\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0808954339981\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808562264067\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808170571789\n",
      "Truth:  0.1698113 Pred:  -0.00782935 Error:  0.177640652282 Loss:  0.0808644036802\n",
      "Truth:  -0.2169811 Pred:  -0.026441 Error:  -0.190540118224 Loss:  0.0809180086238\n",
      "Truth:  0.0 Pred:  -0.0311421 Error:  0.0311420802027 Loss:  0.0808936920979\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808545810787\n",
      "Truth:  0.0 Pred:  -0.0355435 Error:  0.0355434566736 Loss:  0.080832467304\n",
      "Truth:  0.1132075 Pred:  0.123516 Error:  -0.0103089254904 Loss:  0.0807980655762\n",
      "Truth:  -0.3396226 Pred:  -0.00326694 Error:  -0.336355661271 Loss:  0.0809226670368\n",
      "Truth:  -0.245283 Pred:  -0.0222087 Error:  -0.223074272104 Loss:  0.0809919416982\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809528780757\n",
      "Truth:  -0.05660377 Pred:  -0.00115699 Error:  -0.0554467784195 Loss:  0.0809404603057\n",
      "Truth:  0.0 Pred:  -0.00977347 Error:  0.00977347325534 Loss:  0.0809058291684\n",
      "Truth:  -0.6886792 Pred:  -0.0508796 Error:  -0.637799632138 Loss:  0.081176691913\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0811376144375\n",
      "Truth:  0.0 Pred:  -0.0463099 Error:  0.0463099293411 Loss:  0.0811206913641\n",
      "Truth:  -0.02830189 Pred:  -0.0216666 Error:  -0.00663528124918 Loss:  0.0810845158371\n",
      "Truth:  0.0 Pred:  -0.0150753 Error:  0.0150752849877 Loss:  0.0810524725211\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810135311588\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809746275669\n",
      "Truth:  -0.02830189 Pred:  -0.0049328 Error:  -0.0233690882951 Loss:  0.0809467043777\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809078708605\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808690749544\n",
      "Truth:  -0.3773585 Pred:  -0.0155149 Error:  -0.361843563702 Loss:  0.0810050742229\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809662688288\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809275009642\n",
      "Truth:  -0.3867925 Pred:  -0.0105141 Error:  -0.376278402712 Loss:  0.0810702515208\n",
      "Truth:  0.0 Pred:  -0.0100558 Error:  0.0100557710975 Loss:  0.0810359450086\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809971996584\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809584917071\n",
      "Truth:  -0.3018868 Pred:  -0.000794325 Error:  -0.301092475267 Loss:  0.0810646827267\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0810259795647\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080987313707\n",
      "Truth:  -0.009433962 Pred:  -0.044466 Error:  0.035032008248 Loss:  0.08096517724\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0809265778887\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0809061753848\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808676415461\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0808291447592\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807906849706\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807522621271\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807138761754\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806755270624\n",
      "Truth:  -0.04716982 Pred:  -0.00430684 Error:  -0.0428629839463 Loss:  0.0806573915501\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806191062832\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805808577055\n",
      "Truth:  -0.009433962 Pred:  -0.0532321 Error:  0.0437981602126 Loss:  0.0805632414711\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805250562549\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804869075795\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804487953926\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804107196418\n",
      "Truth:  0.0 Pred:  -0.0173082 Error:  0.0173081588 Loss:  0.0803805703055\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803425635024\n",
      "Truth:  0.0 Pred:  -0.000519035 Error:  0.000519035151228 Loss:  0.0803044615796\n",
      "Truth:  0.0 Pred:  -0.00187575 Error:  0.00187575444579 Loss:  0.0802670433033\n",
      "Truth:  0.0 Pred:  -0.0617307 Error:  0.0617307163775 Loss:  0.0802582038532\n",
      "Truth:  -0.1226415 Pred:  -0.0129841 Error:  -0.109657364812 Loss:  0.0802722167993\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0802568246735\n",
      "Truth:  0.0 Pred:  0.000372271 Error:  -0.000372270762455 Loss:  0.0802187844097\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.08018098124\n",
      "Truth:  0.0 Pred:  -0.0243897 Error:  0.0243896767497 Loss:  0.0801544392302\n",
      "Truth:  -0.3490566 Pred:  -0.000794325 Error:  -0.348262275267 Loss:  0.0802819275022\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802441482233\n",
      "Truth:  0.3113208 Pred:  -0.000794325 Error:  0.312115124733 Loss:  0.0803543007062\n",
      "Truth:  -0.03773585 Pred:  -0.0351164 Error:  -0.00261944197974 Loss:  0.0803173895672\n",
      "Truth:  -0.3490566 Pred:  -0.0219402 Error:  -0.327116420831 Loss:  0.0804345224724\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0804325450067\n",
      "Truth:  -0.09433963 Pred:  -0.00194481 Error:  -0.0923948200808 Loss:  0.0804382170196\n",
      "Truth:  0.245283 Pred:  0.0136808 Error:  0.231602230869 Loss:  0.0805098587323\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0804802821035\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.08044255201\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0804130352297\n",
      "Truth:  -0.01886792 Pred:  -0.0225352 Error:  0.00366732959087 Loss:  0.0803767316793\n",
      "Truth:  0.0 Pred:  -0.0112735 Error:  0.0112735144794 Loss:  0.0803440587633\n",
      "Truth:  -0.1886793 Pred:  -0.0252311 Error:  -0.163448195656 Loss:  0.0803833329301\n",
      "Truth:  -0.5 Pred:  -0.00156608 Error:  -0.498433922185 Loss:  0.0805808060474\n",
      "Truth:  -0.1320755 Pred:  -0.000794325 Error:  -0.131281175267 Loss:  0.0806047438988\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805670797085\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805294510505\n",
      "Truth:  0.0 Pred:  -0.00208705 Error:  0.00208705244586 Loss:  0.0804924673642\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0804630522501\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0804336648469\n",
      "Truth:  0.2735849 Pred:  -0.000794325 Error:  0.274379224733 Loss:  0.0805249763158\n",
      "Truth:  0.01886792 Pred:  0.000947609 Error:  0.0179203110965 Loss:  0.0804955152969\n",
      "Truth:  0.0 Pred:  -0.0125928 Error:  0.0125928130001 Loss:  0.0804635761142\n",
      "Truth:  0.0 Pred:  -0.00382114 Error:  0.00382114457898 Loss:  0.0804275430011\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.080390121376\n",
      "Truth:  0.09433963 Pred:  -0.000794325 Error:  0.0951339547329 Loss:  0.0803970466148\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803596744449\n",
      "Truth:  0.0 Pred:  -0.0288938 Error:  0.0288938172162 Loss:  0.0803355234091\n",
      "Truth:  0.0 Pred:  -0.0148306 Error:  0.0148305799812 Loss:  0.080304798764\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802675224049\n",
      "Truth:  -0.5566038 Pred:  -0.0248389 Error:  -0.531764855103 Loss:  0.0804790956629\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.08051247207\n",
      "Truth:  -0.5283019 Pred:  -0.000794325 Error:  -0.527507575267 Loss:  0.0807217394404\n",
      "Truth:  -0.04716982 Pred:  -0.0294799 Error:  -0.0176898916853 Loss:  0.0806922439571\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806548735552\n",
      "Truth:  0.2830189 Pred:  -0.000794325 Error:  0.283813224733 Loss:  0.0807498517465\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0807124893507\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806751618567\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806378692157\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0806006113788\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0805633882973\n",
      "Truth:  0.0 Pred:  -0.000604956 Error:  0.000604955770541 Loss:  0.0805261116388\n",
      "Truth:  0.0 Pred:  -0.00605881 Error:  0.00605880934745 Loss:  0.0804914111252\n",
      "Truth:  0.0 Pred:  -0.00306345 Error:  0.00306344591081 Loss:  0.0804553477972\n",
      "Truth:  0.1886793 Pred:  -0.000794325 Error:  0.189473624733 Loss:  0.0805061011849\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804690086877\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804319506952\n",
      "Truth:  -0.04716982 Pred:  -0.0478424 Error:  0.000672544758253 Loss:  0.0803948705437\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803578814425\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803209267018\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802840062737\n",
      "Truth:  0.02830189 Pred:  -0.000794325 Error:  0.0290962147329 Loss:  0.0802602532382\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0802584006276\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802215605368\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801847545888\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801479827361\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801112449315\n",
      "Truth:  0.2358491 Pred:  -0.000794325 Error:  0.236643424733 Loss:  0.0801836799985\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801469596677\n",
      "Truth:  -0.1132075 Pred:  -0.0519106 Error:  -0.0612969431472 Loss:  0.080138244912\n",
      "Truth:  0.2830189 Pred:  -0.000794325 Error:  0.283813224733 Loss:  0.0802323645884\n",
      "Truth:  -0.5660377 Pred:  -0.0102814 Error:  -0.555756312283 Loss:  0.0804520061347\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0804152297352\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803784872779\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0803758576137\n",
      "Truth:  0.04716982 Pred:  -0.000794325 Error:  0.0479641447329 Loss:  0.0803609144542\n",
      "Truth:  0.0 Pred:  -0.0318731 Error:  0.0318730585277 Loss:  0.0803385698201\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0803019303705\n",
      "Truth:  0.0 Pred:  -0.010138 Error:  0.0101380050182 Loss:  0.0802696265375\n",
      "Truth:  0.0 Pred:  0.0330869 Error:  -0.0330868512392 Loss:  0.0802479133413\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0802113661524\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801748525702\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801383725482\n",
      "Truth:  -0.0754717 Pred:  -0.000794325 Error:  -0.0746773752671 Loss:  0.0801358640515\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.0801687391023\n",
      "Truth:  0.0 Pred:  -0.00173486 Error:  0.00173486303538 Loss:  0.0801327437485\n",
      "Truth:  0.0 Pred:  -0.0258168 Error:  0.0258167609572 Loss:  0.08010782816\n",
      "Truth:  0.2924528 Pred:  -0.000794325 Error:  0.293247124733 Loss:  0.0802055536513\n",
      "Truth:  0.0 Pred:  -0.00947621 Error:  0.00947620533407 Loss:  0.0801731387346\n",
      "Truth:  0.0 Pred:  -0.0171301 Error:  0.0171301327646 Loss:  0.0801442596664\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0801079272786\n",
      "Truth:  0.06603774 Pred:  -0.000794325 Error:  0.0668320647329 Loss:  0.0801018513689\n",
      "Truth:  0.0 Pred:  0.00362856 Error:  -0.00362855778076 Loss:  0.0800668681605\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0800306209985\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799944069691\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079958226027\n",
      "Truth:  -0.06603774 Pred:  -0.00547247 Error:  -0.0605652745817 Loss:  0.079949370798\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0799132434379\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798771490407\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0798755023812\n",
      "Truth:  0.06603774 Pred:  -0.000794325 Error:  0.0668320647329 Loss:  0.0798695573321\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798335321692\n",
      "Truth:  0.02830189 Pred:  -0.000794325 Error:  0.0290962147329 Loss:  0.0798104277441\n",
      "Truth:  0.0 Pred:  -0.00109093 Error:  0.00109093391802 Loss:  0.0797745972963\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797386645063\n",
      "Truth:  0.0 Pred:  -0.0170576 Error:  0.0170576199889 Loss:  0.0797101601659\n",
      "Truth:  0.3113208 Pred:  0.109653 Error:  0.201667312198 Loss:  0.079765595235\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797297155119\n",
      "Truth:  -0.02830189 Pred:  -0.00354518 Error:  -0.0247567109682 Loss:  0.079704750478\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796689309475\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796331439211\n",
      "Truth:  -0.009433962 Pred:  -0.0434968 Error:  0.0340628441745 Loss:  0.0796124771185\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795767481283\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079541051516\n",
      "Truth:  0.7924529 Pred:  0.00435924 Error:  0.788093656097 Loss:  0.0798619539637\n",
      "Truth:  0.08490566 Pred:  -0.000794325 Error:  0.0856999847329 Loss:  0.0798645968024\n",
      "Truth:  -0.06603774 Pred:  -0.000794325 Error:  -0.0652434152671 Loss:  0.0798579808832\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0798222216538\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797864947565\n",
      "Truth:  0.0 Pred:  -0.00403144 Error:  0.00403144210577 Loss:  0.0797522629207\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0797336440913\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796980055724\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796623992182\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796268249853\n",
      "Truth:  0.1603774 Pred:  -0.000794325 Error:  0.161171724733 Loss:  0.0796635900438\n",
      "Truth:  -0.0754717 Pred:  -0.0158638 Error:  -0.0596079200677 Loss:  0.079654551887\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796190292621\n",
      "Truth:  -0.3018868 Pred:  -0.0101528 Error:  -0.291733998129 Loss:  0.0797145335254\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796790158797\n",
      "Truth:  -0.02830189 Pred:  -0.0100613 Error:  -0.0182406157174 Loss:  0.0796513782728\n",
      "Truth:  -0.05660377 Pred:  -0.000794325 Error:  -0.0558094452671 Loss:  0.0796406579792\n",
      "Truth:  -0.04716982 Pred:  -0.00209922 Error:  -0.0450705951681 Loss:  0.0796251208723\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795897072173\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795543253661\n",
      "Truth:  0.1509434 Pred:  -0.000794325 Error:  0.151737724733 Loss:  0.0795867236603\n",
      "Truth:  -0.1226415 Pred:  -0.023863 Error:  -0.0987784824409 Loss:  0.0795953336911\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795599969158\n",
      "Truth:  0.0 Pred:  0.0585821 Error:  -0.0585821159184 Loss:  0.0795505940108\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079515308944\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794800554804\n",
      "Truth:  0.0 Pred:  -0.0276494 Error:  0.0276494137943 Loss:  0.079456854656\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0794554269916\n",
      "Truth:  0.0 Pred:  0.00864224 Error:  -0.00864223856479 Loss:  0.0794237574082\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793886079077\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793534898187\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793184030991\n",
      "Truth:  0.0 Pred:  -0.0219668 Error:  0.0219668280333 Loss:  0.0792927997174\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079257771393\n",
      "Truth:  -0.2075472 Pred:  -0.000794325 Error:  -0.206752875267 Loss:  0.0793146380763\n",
      "Truth:  0.0 Pred:  -0.013309 Error:  0.0133090279996 Loss:  0.0792852106977\n",
      "Truth:  -0.3490566 Pred:  -0.024476 Error:  -0.324580649252 Loss:  0.0793945223905\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793595111666\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793245311192\n",
      "Truth:  -0.3490566 Pred:  -0.021454 Error:  -0.327602612193 Loss:  0.0794350242572\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794000417396\n",
      "Truth:  0.0 Pred:  -0.00341952 Error:  0.00341951870359 Loss:  0.0793662576031\n",
      "Truth:  0.0 Pred:  -0.000539304 Error:  0.000539304455742 Loss:  0.0793312234017\n",
      "Truth:  -0.2075472 Pred:  -0.0208671 Error:  -0.18668006835 Loss:  0.0793789128041\n",
      "Truth:  -0.8773585 Pred:  -0.000794325 Error:  -0.876564175267 Loss:  0.0797329027075\n",
      "Truth:  -0.1415094 Pred:  -0.000794325 Error:  -0.140715075267 Loss:  0.0797599698059\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0797249362455\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079689933757\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796549622991\n",
      "Truth:  0.0 Pred:  0.0142325 Error:  -0.0142325377092 Loss:  0.0796259758461\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795910636888\n",
      "Truth:  0.0 Pred:  0.0517062 Error:  -0.0517061538994 Loss:  0.0795787197712\n",
      "Truth:  0.01886792 Pred:  -0.000794325 Error:  0.0196622447329 Loss:  0.0795522080566\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795173748486\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794825724392\n",
      "Truth:  0.3113208 Pred:  -0.000794325 Error:  0.312115124733 Loss:  0.0795853707389\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795505690401\n",
      "Truth:  0.3773585 Pred:  -0.000794325 Error:  0.378152824733 Loss:  0.0796824022656\n",
      "Truth:  -0.03773585 Pred:  -0.0664109 Error:  0.0286750268106 Loss:  0.0796598923912\n",
      "Truth:  0.0 Pred:  0.0195796 Error:  -0.0195796135813 Loss:  0.0796333902832\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795986287904\n",
      "Truth:  0.0 Pred:  -0.0343634 Error:  0.0343633554876 Loss:  0.0795786925748\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795439858048\n",
      "Truth:  0.0 Pred:  0.0498727 Error:  -0.0498727373779 Loss:  0.0795309205259\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794962653341\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794616406352\n",
      "Truth:  -0.2924528 Pred:  -0.000794325 Error:  -0.291658475267 Loss:  0.0795549549864\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795203349291\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794857452937\n",
      "Truth:  -0.06603774 Pred:  -0.0183163 Error:  -0.0477214599032 Loss:  0.0794717952343\n",
      "Truth:  -0.1509434 Pred:  -0.0304444 Error:  -0.120498990302 Loss:  0.0794898054165\n",
      "Truth:  0.4245283 Pred:  0.0739905 Error:  0.350537828339 Loss:  0.0796087382918\n",
      "Truth:  0.0 Pred:  -0.000998738 Error:  0.000998737639748 Loss:  0.0795742602214\n",
      "Truth:  -0.2641509 Pred:  -0.000794325 Error:  -0.263356575267 Loss:  0.0796548311618\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0796202735341\n",
      "Truth:  0.0 Pred:  -0.0127183 Error:  0.0127183012664 Loss:  0.0795909691222\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795564697157\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0795220005057\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794875614524\n",
      "Truth:  -0.01886792 Pred:  -0.000794325 Error:  -0.0180735952671 Loss:  0.0794607079473\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0794263257868\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793919736675\n",
      "Truth:  0.0 Pred:  -0.00312436 Error:  0.00312435859814 Loss:  0.0793586690321\n",
      "Truth:  0.2264151 Pred:  -0.000794325 Error:  0.227209424733 Loss:  0.0794232044994\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793888987055\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0793546228337\n",
      "Truth:  0.03773585 Pred:  -0.000794325 Error:  0.0385301747329 Loss:  0.0793368266488\n",
      "Truth:  0.0 Pred:  -0.0259514 Error:  0.0259514078498 Loss:  0.0793135650284\n",
      "Truth:  0.0 Pred:  0.00734634 Error:  -0.00734633998945 Loss:  0.0792822204182\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.079248050677\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792139106744\n",
      "Truth:  0.0 Pred:  -0.0324494 Error:  0.0324494317174 Loss:  0.0791935694482\n",
      "Truth:  0.2169811 Pred:  0.0502884 Error:  0.166692709632 Loss:  0.0792316125526\n",
      "Truth:  0.1792453 Pred:  0.0284389 Error:  0.150806363081 Loss:  0.0792627184851\n",
      "Truth:  0.0754717 Pred:  -0.000794325 Error:  0.0762660247329 Loss:  0.0792614167067\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0792273450211\n",
      "Truth:  0.0 Pred:  -0.000794325 Error:  0.000794324732851 Loss:  0.0791933029116\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "for i in range(len(X_validation)):\n",
    "    val = X_validation[i]\n",
    "    y = y_validation[i]\n",
    "    imgs = []\n",
    "    imgs.append(process_line({'path':val, 'steering':y})[0])\n",
    "    pred = model.predict(np.array(imgs))\n",
    "    loss += abs(y - pred[0][0])\n",
    "    print('Truth: ', y, 'Pred: ', pred[0][0], 'Error: ', (y - pred[0][0]), 'Loss: ', loss/(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.save('model.h5')\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from keras.models import load_model, model_from_json\n",
    "\n",
    "#json_file = open('model.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "#    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#json_file = open('model.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#model.load_weights(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
